{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdcadbe9",
   "metadata": {},
   "source": [
    "## **Graph Neural Networks for Capturing Dependencies in Graph Structured Data (Part 1/2)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb77d45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **Graph Neural Networks for Capturing Dependencies in Graph-Structured Data**\n",
    "\n",
    "\n",
    "**1. Graph-Structured Data**\n",
    "\n",
    "Many real-world systems are naturally represented as **graphs**:\n",
    "\n",
    "* **Nodes (vertices)** represent entities.\n",
    "* **Edges** represent relationships or interactions.\n",
    "\n",
    "Examples:\n",
    "\n",
    "* Molecules → atoms as nodes, chemical bonds as edges.\n",
    "* Social networks → people as nodes, friendships as edges.\n",
    "* Citation networks → papers as nodes, citations as edges.\n",
    "\n",
    "A graph is represented as:\n",
    "\n",
    "$$G = (V, E)$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $`V`$ = set of nodes,\n",
    "* $`E`$ = set of edges.\n",
    "\n",
    "Each node may have features:\n",
    "\n",
    "$$X \\in \\mathbb{R}^{|V| \\times d}$$\n",
    "\n",
    "And an adjacency matrix:\n",
    "\n",
    "$$A \\in \\mathbb{R}^{|V| \\times |V|}$$\n",
    "\n",
    "\n",
    "\n",
    "**2. Why Standard Neural Networks Do Not Work**\n",
    "\n",
    "Traditional neural networks assume:\n",
    "\n",
    "* Fixed input shape (e.g., image grid),\n",
    "* Spatial locality (neighboring pixels).\n",
    "\n",
    "Graphs are **irregular**:\n",
    "\n",
    "* Nodes have different numbers of neighbors.\n",
    "* No fixed spatial ordering.\n",
    "* Structure itself carries meaning.\n",
    "\n",
    "Thus, we require models that:\n",
    "\n",
    "1. Respect **permutation invariance**.\n",
    "2. Aggregate **neighbor information**.\n",
    "3. Preserve **graph topology**.\n",
    "\n",
    "\n",
    "\n",
    "**3. Core Idea of Graph Neural Networks**\n",
    "\n",
    "Graph Neural Networks operate by **message passing**:\n",
    "\n",
    "Each node updates its representation by aggregating features from its neighbors.\n",
    "\n",
    "For node $`i`$ at layer $`k`$, representation is:\n",
    "\n",
    "$$h_i^{(k+1)} = \\mathrm{UPDATE}\\left( h_i^{(k)}, \\mathrm{AGG}\\left( \\{ h_j^{(k)} : j \\in \\mathcal{N}(i) \\} \\right) \\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $`\\mathcal{N}(i)`$ is the neighbor set of node $`i`$,\n",
    "* $`\\mathrm{AGG}`$ is a permutation-invariant function (mean, sum, max),\n",
    "* $`\\mathrm{UPDATE}`$ is typically a learned transformation.\n",
    "\n",
    "\n",
    "\n",
    "**4. Graph Convolutional Networks (GCN)**\n",
    "\n",
    "The most widely used GNN model:\n",
    "\n",
    "$$H^{(k+1)} = \\sigma\\left( \\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}} H^{(k)} W^{(k)} \\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $`H^{(k)}`$ is node representations at layer $`k`$,\n",
    "* $`\\tilde{A} = A + I`$ adds self-connections,\n",
    "* $`\\tilde{D}`$ is the degree matrix of $`\\tilde{A}`$,\n",
    "* $`W^{(k)}`$ are learnable parameters,\n",
    "* $`\\sigma`$ is a non-linearity.\n",
    "\n",
    "This performs **Laplacian smoothing**:\n",
    "Nodes with edges become more similar across layers.\n",
    "\n",
    "\n",
    "\n",
    "**5. Graph Attention Networks (GAT)**\n",
    "\n",
    "Instead of averaging neighbors equally, learn **attention weights**:\n",
    "\n",
    "$$e_{ij} = \\mathrm{a}(W h_i, W h_j)$$\n",
    "\n",
    "Normalized via softmax:\n",
    "\n",
    "$$\\alpha_{ij} = \\frac{\\exp(e_{ij})}{\\sum_{k \\in \\mathcal{N}(i)} \\exp(e_{ik})}$$\n",
    "\n",
    "Updated representation:\n",
    "\n",
    "$$h_i^{(k+1)} = \\sigma\\left( \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{ij} W h_j \\right)$$\n",
    "\n",
    "This allows the model to learn **which neighbors are important**.\n",
    "\n",
    "\n",
    "\n",
    "**6. Message Passing Neural Network View**\n",
    "\n",
    "Generalized framework:\n",
    "\n",
    "1. **Message computation**:\n",
    "\n",
    "$$m_{ij}^{(k)} = \\phi_m(h_i^{(k)}, h_j^{(k)}, e_{ij})$$\n",
    "\n",
    "2. **Message aggregation**:\n",
    "\n",
    "$$m_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i)} m_{ij}^{(k)}$$\n",
    "\n",
    "3. **Node update**:\n",
    "\n",
    "$$h_i^{(k+1)} = \\phi_h(h_i^{(k)}, m_i^{(k)})$$\n",
    "\n",
    "This is flexible and applies to molecules, social networks, scenes, and knowledge graphs.\n",
    "\n",
    "\n",
    "\n",
    "**7. Capturing Graph-Level, Node-Level, and Edge-Level Patterns**\n",
    "\n",
    "| Task Type            | Output                 | Description                            |\n",
    "| -------------------- | ---------------------- | -------------------------------------- |\n",
    "| Node Classification  | Label per node         | Example: Detect toxic atom in molecule |\n",
    "| Graph Classification | Single label per graph | Example: Predict molecule solubility   |\n",
    "| Link Prediction      | Predict missing edges  | Example: Recommend friends             |\n",
    "\n",
    "Pooling methods (sum/mean attention pooling) allow generating **graph-level embeddings**.\n",
    "\n",
    "\n",
    "\n",
    "**8. Why GNNs Capture Dependencies Well**\n",
    "\n",
    "* Local neighborhood aggregation captures **local structure**.\n",
    "* Stacking layers propagates **global structure**.\n",
    "* Graph attention focuses on **important interactions**.\n",
    "\n",
    "This makes GNNs powerful for:\n",
    "\n",
    "* Relationship modeling,\n",
    "* Structured environments,\n",
    "* Systems with complex interactions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f3418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b16f0a",
   "metadata": {},
   "source": [
    "### **Introduction to graph data**\n",
    "\n",
    "- Graphs are a kind of data structure that is nonlinear and abstract.\n",
    "- Graphs can be defined to have certain properties that may require different representations.\n",
    "\n",
    "![Types of Graphs](./figures/18_01.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04f7e6",
   "metadata": {},
   "source": [
    "### **Undirected graphs**\n",
    "\n",
    "- consists of `nodes` (vertices) that are connected via `edges` where the order of the nodes and their connection does not matter.\n",
    "\n",
    "![Undirected graphs](./figures/18_02.png)\n",
    "\n",
    "- Other common examples of data that can be represented as `undirected graphs` include \n",
    "  - `images`, \n",
    "  - `protien-protein interaction networks`, and\n",
    "  - `point clouds`.\n",
    "\n",
    "- Mathematically, an undirected graph `G` is a pair of `(V, E)`, where `V` is a set of the graph's nodes, and `E` is the set of edges making up the paired nodes.\n",
    "\n",
    "- The graph can be encoded as $|V| \\times |V|$ `adjacency matrix A`.\n",
    "\n",
    "- Each element $x_{ij}$ in matrix $A$ is either a `1` or a `0`, with `1` denoting an edge between `nodes` $i$ and $j$ (vice versa, `0` denotes the absence of an edge).\n",
    "\n",
    "- An additional property of an undirected graph `A` is that $x_{ij} = x_{ji}$\n",
    "\n",
    "* `Adjacency Matrix` is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph. An adjacency matrix is a simple and straightforward way to represent graphs and is particularly useful for dense graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ccecc",
   "metadata": {},
   "source": [
    "### **Directed graphs**\n",
    "\n",
    "- `Directed graphs` connects nodes via `directed edges`. \n",
    "- Mathematically, they are defined in the same way as an undirected graph, except that $E$, the set of edges, is a set of `ordered pairs`.\n",
    "- Element `A` is that $x_{ij} \\neq x_{ji}$\n",
    "\n",
    "\n",
    "![Directed Graph](./figures/18_03.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac390cc",
   "metadata": {},
   "source": [
    "### **Labeled graphs**\n",
    "\n",
    "- Many graphs we are interested in working with have additional information associated with each of their nodes and edges.\n",
    "\n",
    "- Given graph $G$, defined by the node set and edge set tuple $(V, E)$, we define a $|V| \\times f_{V}$ node feature matrix X, where $f_{V}$ is the length of the label vector of each node. \n",
    "- For edge labels, we define an $|E| \\times f_{E}$ edge feature matrix $X_{E}$, where $f_{E}$ is the length of the label vector of each edge.\n",
    "\n",
    "\n",
    "\n",
    "### **Representing molecules as graphs**\n",
    "\n",
    "- As a chemical overview, molecules can be thought of as groups of atoms held together by chemical bonds. There are different atoms corresponding to different chemical elements, for example, common elements include `carbon (C)`, `oxygen (O)`, `nitrogen (N)`, and `hydrogen (H)`. Also, there are different kinds\n",
    "of bonds that form the connection between atoms, for example, `single or double bonds`.\n",
    "\n",
    "\n",
    "![Graph representation of a caffeine molecule](./figures/18_04.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f8805",
   "metadata": {},
   "source": [
    "## **Understanding graph convolutions**\n",
    "\n",
    "### **The motivation behind using graph convolutions**\n",
    "\n",
    "![Different adjacency matrices representing the same graph](./figures/18_05.png)\n",
    "\n",
    "- A convolutional approach is also desirable for graphs because it can function with a fixed parameter set for graphs of different sizes. This property is arguably even more important for graphs than images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d977c717",
   "metadata": {},
   "source": [
    "### **Implementing a basic graph convolution**\n",
    "\n",
    "![A representation of a graph](./figures/18_06.png)\n",
    "\n",
    "- The figure above depicts an undirected graph with node labels specified by an $n×n$ adjacency matrix $A$ and $n \\times f_{in}$ node feature matrix $X$, where the only feature is a one-hot representation of each node’s color green `(G)`, blue `(B)`, or orange `(O)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd34bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0]\n",
      " [1 0 1 0]\n",
      " [1 1 0 1]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx \n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "#Hex codes for colors if we draw graph\n",
    "blue, orange, green = \"#1f77b4\", \"#ff7f0e\",\"#2ca02c\"\n",
    "\n",
    "G.add_nodes_from([(1, {\"color\": blue}),\n",
    "                  (2, {\"color\": orange}),\n",
    "                  (3, {\"color\": blue}),\n",
    "                  (4, {\"color\": green})])\n",
    "\n",
    "G.add_edges_from([(1, 2),(2, 3),(1, 3),(3, 4)])\n",
    "A = np.asarray(nx.adjacency_matrix(G).todense())\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aeb7343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def build_graph_color_label_representation(G,mapping_dict):\n",
    "    one_hot_idxs = np.array([mapping_dict[v] for v in \n",
    "                             nx.get_node_attributes(G, 'color').values()])\n",
    "    one_hot_encoding = np.zeros((one_hot_idxs.size,len(mapping_dict)))\n",
    "    one_hot_encoding[np.arange(one_hot_idxs.size),one_hot_idxs] = 1\n",
    "    return one_hot_encoding\n",
    "\n",
    "X = build_graph_color_label_representation(G, {green: 0, blue: 1, orange: 2})\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e16cf",
   "metadata": {},
   "source": [
    "- To draw the graph constructed in the preceding code, we can then use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a7240e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_map = nx.get_node_attributes(G, 'color').values()\n",
    "nx.draw(G, with_labels=True, node_color=color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1668b0",
   "metadata": {},
   "source": [
    "- In the preceding code example, we first initiated a new Graph object from `NetworkX`. We then added nodes `1` to `4` together with color specifications for visualization. After adding the nodes, we specified their connections (edges). Using the `adjacency_matrix` constructor from `NetworkX`, we create the\n",
    "adjacency matrix A, and our custom `build_graph_color_label_representation` function creates the node label matrix X from the information we added to the Graph object earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6f416b",
   "metadata": {},
   "source": [
    "- With graph convolutions, we can interpret each row of $X$ as being an embedding of the information that is stored at the node corresponding to that row. Graph convolutions update the embeddings at each node based on the embeddings of their neighbors and themselves. For our example implementation, the graph convolution will take the following form:\n",
    "\n",
    "$$x'_{i} = x_{i}W_1 = \\sum_{j \\in N(i)} x_{j}W_2 + b$$\n",
    "\n",
    "where\n",
    "- $x'$ is the updated embedding for node `i`;\n",
    "- $W_1$ and $W_2$ are $f_{in} \\times f_{out}$ matrices of learnable filter weights;\n",
    "- and $b$ is a learnable bias vector of length $f_{out}$.\n",
    "\n",
    "\n",
    "The two weight matrices $W_{1}$ and $W_{2}$ can be considered filter banks, where each column is an individual filter. Note that this filter design is most effective when the locality prior on graph data holds. If a value at a node is highly correlated with the value at another node many edges away, a single convolution will not capture that relationship. Stacking convolutions will capture more distant relationships, as illustrated below;\n",
    "\n",
    "\n",
    "![Capturing relationships from a graph](./figures/18_07.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b5788",
   "metadata": {},
   "source": [
    "**How to implement the sum over neighbors in matrix form**\n",
    "\n",
    "- This is where we utilize the adjacency matrix $A$.\n",
    "- The matrix form of this convolution is $XW_{1} + AXW_{2}$.\n",
    "- Here, the `adjacency matrix`, consisting of `1s` and `0s`, acts as a mask to select nodes and compute the desired sums. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50844ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1783f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_in, f_out = X.shape[1], 6\n",
    "W_1 = np.random.rand(f_in, f_out) \n",
    "W_2 = np.random.rand(f_in, f_out) \n",
    "h = np.dot(X,W_1) + np.dot(np.dot(A, X), W_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3684bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.079792  , 1.43349822, 2.1784995 , 2.41965928, 0.79441012,\n",
       "        1.69699761],\n",
       "       [1.85701426, 1.21039713, 2.77455182, 2.11244676, 0.45011755,\n",
       "        2.6277335 ],\n",
       "       [2.8752309 , 1.89531396, 2.57578408, 2.64667589, 0.82898471,\n",
       "        1.92076214],\n",
       "       [1.58629088, 1.02768234, 1.63838979, 1.38677185, 0.26792717,\n",
       "        1.57302162]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8c9f3",
   "metadata": {},
   "source": [
    "- Computing a forward pass of a graph convolution is that easy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158041c8",
   "metadata": {},
   "source": [
    "- Ultimately, we want a graph convolutional layer to update the representation of the node information encoded in $X$ by utilizing the structural (connectivity) information provided by $A$. There are many potential ways to do this, and this plays out in the numerous kinds of graph convolutions that have\n",
    "been developed.\n",
    "\n",
    "![The convolutions implemented on the graph and the message form](./figures/18_08.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012502b8",
   "metadata": {},
   "source": [
    "## **Implementing a GNN in PyTorch from scratch**\n",
    "\n",
    "\n",
    "#### **Defining the NodeNetwork model**\n",
    "\n",
    "- PyTorch from-scratch implementation of a GNN\n",
    "- top-down approach, starting with the main neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d426fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b08639",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_1 = BasicGraphConvolutionLayer(input_features, 32)\n",
    "        self.conv_2 = BasicGraphConvolutionLayer(32, 32)\n",
    "        self.fc_1 = torch.nn.Linear(32, 16)\n",
    "        self.out_layer = torch.nn.Linear(16, 2)\n",
    "    \n",
    "    def forward(self, X, A,batch_mat):\n",
    "        x = self.conv_1(X, A).clamp(0)\n",
    "        x = self.conv_2(x, A).clamp(0)\n",
    "        output = global_sum_pool(x, batch_mat)\n",
    "        output = self.fc_1(output)\n",
    "        output = self.out_layer(output)\n",
    "        return F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a9c95",
   "metadata": {},
   "source": [
    "**The NodeNetwork model we just defined can be summarized as follows:**\n",
    "\n",
    "- Perform two graph convolutions (`self.conv_1` and `self.conv_2`)\n",
    "- Pool all the node embeddings via `global_sum_pool`, which we will define later\n",
    "- Run the pooled embeddings through two fully connected layers (`self.fc_1` and `self.out_layer`)\n",
    "- Output a class-membership probability via `softmax`.\n",
    "\n",
    "\n",
    "![A visualization of each neural network layer](./figures/18_09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b55a066",
   "metadata": {},
   "source": [
    "#### **Coding the NodeNetwork’s graph convolution layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1be9b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGraphConvolutionLayer(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.W2 = Parameter(torch.rand(\n",
    "             (in_channels, out_channels), dtype=torch.float32))\n",
    "        self.W1 = Parameter(torch.rand(\n",
    "             (in_channels, out_channels), dtype=torch.float32))\n",
    "         \n",
    "        self.bias = Parameter(torch.zeros(\n",
    "                 out_channels, dtype=torch.float32))\n",
    "    \n",
    "    def forward(self, X, A):\n",
    "        potential_msgs = torch.mm(X, self.W2)\n",
    "        propagated_msgs = torch.mm(A, potential_msgs)\n",
    "        root_update = torch.mm(X, self.W1)\n",
    "        output = propagated_msgs + root_update + self.bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07798bd",
   "metadata": {},
   "source": [
    "- As with fully connected layers and image convolutional layers, we add a bias term so that the intercept of the linear combination of the layer outputs (prior to the application of a nonlinearity like ReLU) can vary. \n",
    "\n",
    "- The `forward()` method implements the matrix form of the forward pass, which we discussed in the previous subsection, with the addition of a `bias` term.\n",
    "\n",
    "- To try out the `BasicGraphConvolutionLayer`, let’s apply it to the graph and adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c864e0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (4, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X.shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a2651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A.shape: (4, 4)\n"
     ]
    }
   ],
   "source": [
    "print('A.shape:', A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ce34a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "basiclayer = BasicGraphConvolutionLayer(3, 8)\n",
    "out = basiclayer(X=torch.tensor(X, dtype=torch.float32),\n",
    "                 A=torch.tensor(A, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "print('Output shape:', out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dc25f5",
   "metadata": {},
   "source": [
    "### **Adding a global pooling layer to deal with varying graph sizes**\n",
    "\n",
    "- Next, we define the `global_sum_pool()` function that was used in the `NodeNetwork` class, where `global_sum_pool()` implements a global pooling layer. \n",
    "- Global pooling layers aggregate all of a graph’s node embeddings into a fixed-sized output. \n",
    "- `global_sum_pool()` sums all the node embeddings of a graph.\n",
    "- Summing all the node embeddings results in a loss of information, so reshaping the data would be preferable, but since graphs can have different sizes, this is not feasible.\n",
    "- Global pooling can be done with any permutation invariant function, for example, `sum`, `max`, and `mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b851dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_sum_pool(X, batch_mat):\n",
    "    if batch_mat is None or batch_mat.dim() == 1:\n",
    "        return torch.sum(X, dim=0).unsqueeze(0)\n",
    "    else:\n",
    "        return torch.mm(batch_mat, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a66d8d",
   "metadata": {},
   "source": [
    "- If data is not batched or the batch size is one, this function just sums over the current node embeddings. Otherwise, the embeddings are multiplied with `batch_mat`, which has a structure based on how graph data is batched.\n",
    "\n",
    "- When all data in a dataset has the same dimensionality, batching the data is as straightforward as adding a dimension by stacking the data.\n",
    "\n",
    "- Since graph sizes vary, this approach is not feasible with graph data unless padding is used. However, padding can be inefficient in cases where graph sizes\n",
    "can vary substantially.\n",
    "\n",
    "\n",
    "![How to deal with varying graph sizes](./figures/18_10.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039f33a",
   "metadata": {},
   "source": [
    "- This is the purpose of `batch_mat` in `global_sum_pool()` to serve as a graph selection mask that keeps the graphs in the batch separate.\n",
    "\n",
    "- We can generate this mask for graphs of sizes $n_{1}, ..., n_{k}$ with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1151bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_tensor(graph_sizes):\n",
    "    starts = [sum(graph_sizes[:idx]) for idx in range(len(graph_sizes))]\n",
    "    stops = [starts[idx]+graph_sizes[idx] for idx in range(len(graph_sizes))]\n",
    "    tot_len = sum(graph_sizes)\n",
    "    batch_size = len(graph_sizes)\n",
    "    batch_mat = torch.zeros([batch_size, tot_len]).float()\n",
    "    for idx, starts_and_stops in enumerate(zip(starts, stops)):\n",
    "        start = starts_and_stops[0]\n",
    "        stop = starts_and_stops[1]\n",
    "        batch_mat[idx, start:stop] = 1\n",
    "    return batch_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe4366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch is a list of dictionaries each containing\n",
    "# the representation and label of a graph\n",
    "def collate_graphs(batch):\n",
    "    adj_mats = [graph['A'] for graph in batch]\n",
    "    sizes = [A.size(0) for A in adj_mats]\n",
    "    tot_size = sum(sizes)\n",
    "    # create batch matrix\n",
    "    batch_mat = get_batch_tensor(sizes)\n",
    "    # combine feature matrices\n",
    "    feat_mats = torch.cat([graph['X'] for graph in batch],dim=0)\n",
    "    # combine labels\n",
    "    labels = torch.cat([graph['y'] for graph in batch], dim=0)\n",
    "    # combine adjacency matrices\n",
    "    batch_adj = torch.zeros([tot_size, tot_size], dtype=torch.float32)\n",
    "    accum = 0\n",
    "    for adj in adj_mats:\n",
    "        g_size = adj.shape[0]\n",
    "        batch_adj[accum:accum+g_size, accum:accum+g_size] = adj\n",
    "        accum = accum + g_size\n",
    "    repr_and_label = {\n",
    "            'A': batch_adj, \n",
    "            'X': feat_mats,\n",
    "            'y': labels,\n",
    "            'batch' : batch_mat}\n",
    "\n",
    "    return repr_and_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def8460b",
   "metadata": {},
   "source": [
    "### **Preparing the DataLoader**\n",
    "\n",
    "- This function takes a `NetworkX` graph and returns a dictionary containing its adjacency matrix `A`, its node feature matrix `X`, and a binary label `y`.\n",
    "\n",
    "- Since we won’t actually be training this model on a real-world task, we just set the labels arbitrarily. \n",
    "\n",
    "- Then, `nx.adjacency_matrix()` takes a NetworkX graph and returns a sparse representation that we convert to a dense `np.array` form using `todense()`.\n",
    "\n",
    "- We’ll now construct graphs and use the `get_graph_dict` function to convert `NetworkX` graphs to a format our network can handle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b95d7e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_dict(G, mapping_dict):\n",
    "    # build dictionary representation of graph G\n",
    "    A = torch.from_numpy(np.asarray(nx.adjacency_matrix(G).todense())).float()\n",
    "    # build_graph_color_label_representation() was introduced with the first example graph\n",
    "    X = torch.from_numpy(build_graph_color_label_representation(G,mapping_dict)).float()\n",
    "    # kludge since there is not specific task for this example\n",
    "    y = torch.tensor([[1, 0]]).float()\n",
    "    return {'A': A, 'X': X, 'y': y, 'batch': None}\n",
    "    \n",
    "# building 4 graphs to treat as a dataset\n",
    "\n",
    "blue, orange, green = \"#1f77b4\", \"#ff7f0e\",\"#2ca02c\"\n",
    "mapping_dict = {green: 0, blue: 1, orange: 2}\n",
    "\n",
    "G1 = nx.Graph()\n",
    "G1.add_nodes_from([(1, {\"color\": blue}),\n",
    "                   (2, {\"color\": orange}),\n",
    "                   (3, {\"color\": blue}),\n",
    "                   (4, {\"color\": green})])\n",
    "G1.add_edges_from([(1, 2), (2, 3),(1, 3), (3, 4)])\n",
    "G2 = nx.Graph()\n",
    "G2.add_nodes_from([(1, {\"color\": green}),\n",
    "                   (2, {\"color\": green}),\n",
    "                   (3, {\"color\": orange}),\n",
    "                   (4, {\"color\": orange}),\n",
    "                   (5,{\"color\": blue})])\n",
    "G2.add_edges_from([(2, 3),(3, 4),(3, 1),(5, 1)])\n",
    "G3 = nx.Graph()\n",
    "G3.add_nodes_from([(1, {\"color\": orange}),\n",
    "                   (2, {\"color\": orange}),\n",
    "                   (3, {\"color\": green}),\n",
    "                   (4, {\"color\": green}),\n",
    "                   (5, {\"color\": blue}),\n",
    "                   (6, {\"color\":orange})])\n",
    "G3.add_edges_from([(2, 3), (3, 4), (3, 1), (5, 1), (2, 5), (6, 1)])\n",
    "G4 = nx.Graph()\n",
    "G4.add_nodes_from([(1, {\"color\": blue}), (2, {\"color\": blue}), (3, {\"color\": green})])\n",
    "G4.add_edges_from([(1, 2), (2, 3)])\n",
    "graph_list = [get_graph_dict(graph,mapping_dict) for graph in [G1, G2, G3, G4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "986e3082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A': tensor([[0., 1., 1., 0.],\n",
       "          [1., 0., 1., 0.],\n",
       "          [1., 1., 0., 1.],\n",
       "          [0., 0., 1., 0.]]),\n",
       "  'X': tensor([[0., 1., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.]]),\n",
       "  'y': tensor([[1., 0.]]),\n",
       "  'batch': None},\n",
       " {'A': tensor([[0., 0., 1., 0., 1.],\n",
       "          [0., 0., 1., 0., 0.],\n",
       "          [1., 1., 0., 1., 0.],\n",
       "          [0., 0., 1., 0., 0.],\n",
       "          [1., 0., 0., 0., 0.]]),\n",
       "  'X': tensor([[1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [0., 1., 0.]]),\n",
       "  'y': tensor([[1., 0.]]),\n",
       "  'batch': None},\n",
       " {'A': tensor([[0., 0., 1., 0., 1., 1.],\n",
       "          [0., 0., 1., 0., 1., 0.],\n",
       "          [1., 1., 0., 1., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0.],\n",
       "          [1., 1., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0.]]),\n",
       "  'X': tensor([[0., 0., 1.],\n",
       "          [0., 0., 1.],\n",
       "          [1., 0., 0.],\n",
       "          [1., 0., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 1.]]),\n",
       "  'y': tensor([[1., 0.]]),\n",
       "  'batch': None},\n",
       " {'A': tensor([[0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.]]),\n",
       "  'X': tensor([[0., 1., 0.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 0.]]),\n",
       "  'y': tensor([[1., 0.]]),\n",
       "  'batch': None}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539b88f",
   "metadata": {},
   "source": [
    "- the graphs the preceeding code generates:\n",
    "\n",
    "![Four generated graphs](./figures/18_11.png)\n",
    "\n",
    "\n",
    "- This code block constructs four `NetworkX` graphs and stores them in a list. Here, the constructor of `nx.Graph()` initializes an empty graph, and `add_nodes_from()` adds nodes to the empty graph from a list of tuples. The first item in each tuple is the node’s name, and the second item is a dictionary of\n",
    "that node’s attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d78cc3",
   "metadata": {},
   "source": [
    "- The `add_edges_from()` method of a graph takes a list of tuples where each tuple defines an edge between its elements (nodes). Now, we can construct a PyTorch Dataset for these graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2709205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class ExampleDataset(Dataset):\n",
    "    \n",
    "    # Simple PyTorch dataset that will use our list of graphs\n",
    "    def __init__(self, graph_list):\n",
    "        self.graphs = graph_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        mol_rep = self.graphs[idx]\n",
    "        return mol_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc703a63",
   "metadata": {},
   "source": [
    "- While using a custom Dataset may seem like unnecessary effort, it allows us to exhibit how `collate_graphs()` can be used in a DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81207b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = ExampleDataset(graph_list)\n",
    "# Note how we use our custom collate function\n",
    "loader = DataLoader(dset, batch_size=2, shuffle=False, collate_fn=collate_graphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ddba8",
   "metadata": {},
   "source": [
    "### **Using the NodeNetwork to make predictions**\n",
    "\n",
    "- After we have defined all the necessary functions and set up the DataLoader, we now initialize a new `NodeNetwork` and apply it to our graph data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba1e09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "node_features = 3\n",
    "net = NodeNetwork(node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc33bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = []\n",
    "\n",
    "for b in loader:\n",
    "    batch_results.append(net(b['X'], b['A'], b['batch']).detach())\n",
    "\n",
    "# provide a single input graph to the model directly without the DataLoader:\n",
    "G1_rep = dset[1]\n",
    "G1_single = net(G1_rep['X'], G1_rep['A'], G1_rep['batch']).detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fed106",
   "metadata": {},
   "source": [
    "- We can now compare the results from applying the GNN to a single graph (G1_single) and to the first graph from the DataLoader (also the first graph, G1, which we guaranteed, since we set shuffle=False) to double-check that the batch loader works correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1144a080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1_batch = batch_results[0][1]\n",
    "torch.all(torch.isclose(G1_single, G1_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4112ca",
   "metadata": {},
   "source": [
    "- Note that for brevity, we didn’t include a training loop; however, the GNN model could be trained in a regular fashion by computing the loss between predicted and true class labels, backpropagating the loss via `.backward()`, and updating the model weights via a gradient descent-based optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432814b",
   "metadata": {},
   "source": [
    "---\n",
    "**Mathematics of Graph Convolutional Neural Networks (GCNs)**\n",
    "\n",
    "\n",
    "**1. Inputs**\n",
    "\n",
    "* Node features:\n",
    "  $`X \\in \\mathbb{R}^{N \\times d}`$\n",
    "  (N nodes, feature dimension d)\n",
    "\n",
    "* Adjacency matrix:\n",
    "  $`A \\in \\mathbb{R}^{N \\times N}`$\n",
    "\n",
    "* Add self-loops:\n",
    "  $`\\tilde{A} = A + I`$\n",
    "\n",
    "\n",
    "\n",
    "**2. Normalization**\n",
    "\n",
    "Compute degree matrix:\n",
    "$$\\tilde{D}_{ii} = \\sum_j \\tilde{A}_{ij}$$\n",
    "\n",
    "Normalize adjacency:\n",
    "$$\\hat{A} = \\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}}$$\n",
    "\n",
    "This prevents feature scaling imbalance.\n",
    "\n",
    "\n",
    "\n",
    "**3. Core GCN Layer**\n",
    "\n",
    "$$H^{(k+1)} = \\sigma\\left( \\hat{A} \\, H^{(k)} \\, W^{(k)} \\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $`H^{(k)}`$: node embeddings at layer k\n",
    "  ($`H^{(0)} = X`$)\n",
    "* $`W^{(k)}`$: learnable weights\n",
    "* $`\\sigma`$: activation (e.g., ReLU)\n",
    "\n",
    "\n",
    "\n",
    "**4. Node-wise Interpretation**\n",
    "\n",
    "For each node $`i`$:\n",
    "\n",
    "$$h_i^{(k+1)} = \\sigma\\!\\left(\\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\frac{1}{\\sqrt{\\tilde{D}_{ii}\\tilde{D}_{jj}}}\\, h_j^{(k)} W^{(k)} \\right)$$\n",
    "\n",
    "→ Each node updates its state using a **weighted average of its neighbors’ states + itself**.\n",
    "\n",
    "\n",
    "\n",
    "**5. Summary**\n",
    "\n",
    "| Step           | Operation                                               | Purpose                               |\n",
    "| -------------- | ------------------------------------------------------- | ------------------------------------- |\n",
    "| Add self-loops | $`\\tilde{A} = A + I`$                                   | Include each node’s own features      |\n",
    "| Normalize      | $`\\hat{A} = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}`$ | Stabilize message passing             |\n",
    "| GCN update     | $`H' = \\hat{A} H W`$                                    | Aggregate + learn new representations |\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
