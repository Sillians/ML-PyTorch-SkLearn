{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bc9d5f1",
   "metadata": {},
   "source": [
    "# **Modeling Sequential Data Using Recurrent Neural Networks (Part 2/3)**\n",
    "\n",
    "## Project one: predicting the sentiment of IMDb movie reviews\n",
    "\n",
    "- Sentiment analysis is concerned with analyzing the expressed opinion of a sentence or a text document.\n",
    "\n",
    "- we will implement a `multilayer RNN` for sentiment analysis using a many-to-one architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d61a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edd0f1d",
   "metadata": {},
   "source": [
    "### Preparing the movie review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8a48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97336f",
   "metadata": {},
   "source": [
    "- Each set has `25,000` samples. And each sample of the datasets consists of two elements, the sentiment label representing the target label we want to predict (neg refers to negative sentiment and pos refers to positive sentiment), and the movie review text (the input features). The text component of these movie reviews is sequences of words, and the RNN model classifies each sequence as a positive (1) or negative (0) review.\n",
    "\n",
    "\n",
    "- However, before we can feed the data into an RNN model, we need to apply several preprocessing steps:\n",
    "  - Split the training dataset into separate training and validation partitions.\n",
    "  - Identify the unique words in the training dataset.\n",
    "  - Map each unique word to a unique integer and encode the review text into encoded integers.\n",
    "  - Divide the dataset into mini-batches as input to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2ef08",
   "metadata": {},
   "source": [
    "- **Torchtext is deprecated**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b73e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext.datasets import IMDB\n",
    "# from torch.utils.data.dataset import random_split\n",
    "\n",
    "# # Step 1: load and create the datasets\n",
    "# train_dataset = IMDB(split='train')\n",
    "# test_dataset = IMDB(split='test')\n",
    "\n",
    "# test_dataset = list(test_dataset)   #datapipe to list\n",
    "\n",
    "# torch.manual_seed(1)\n",
    "# train_dataset, valid_dataset = random_split(\n",
    "#     list(train_dataset), [20000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f8632",
   "metadata": {},
   "source": [
    "- Modern IMDB Dataset Loading (No Torchtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36bf982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/ML-PyTorch-SkLearn/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Step1: load IMDB from HuggingFace datasets\n",
    "imdb = load_dataset(\"imdb\") # returns the dict-like dataset object\n",
    "\n",
    "train_dataset = imdb[\"train\"]\n",
    "test_dataset = imdb[\"test\"]\n",
    "\n",
    "# convert test dataset to list\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "# split train into train + validation\n",
    "torch.manual_seed(1)\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    list(train_dataset), [20000, 5000]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00201248",
   "metadata": {},
   "source": [
    "- `train_dataset` → 20,000 examples\n",
    "- `valid_dataset` → 5,000 examples\n",
    "- `test_dataset` → 25,000 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fda084",
   "metadata": {},
   "source": [
    "- The code for collecting unique tokens is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072a4bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 69023\n"
     ]
    }
   ],
   "source": [
    "# step 2: find unique tokens (words)\n",
    "import re \n",
    "from collections import Counter\n",
    "\n",
    "token_counts = Counter()\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub(r'<[^>]*>', '', text)\n",
    "    emoticons = re.findall(r'(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub(r'[\\W]+', ' ', text.lower()) + ' '.join(emoticons).replace('-', '')\n",
    "    return text.split()\n",
    "\n",
    "# train_dataset is the HF dataset split from earlier\n",
    "for example in train_dataset:  # example is a dict: {\"text\": ..., \"label\": ...}\n",
    "    tokens = tokenizer(example[\"text\"])\n",
    "    token_counts.update(tokens)\n",
    "\n",
    "print(\"Vocab-size:\", len(token_counts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae0ac1b",
   "metadata": {},
   "source": [
    "- Next, we are going to map each unique word to a unique integer. This can be done manually using a Python dictionary, where the keys are the unique tokens (words) and the value associated with each key is a unique integer. However, the `torchtext` package already provides a class, `Vocab`, which we can use to create such a mapping and encode the entire dataset. First, we will create a vocab object by passing the ordered dictionary mapping tokens to their corresponding occurrence frequencies (the ordered dictionary is the sorted `token_counts`). Second, we will prepend two special tokens to the vocabulary – the padding and the unknown token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4505b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# Step 3 — Build vocabulary dictionary manually\n",
    "sorted_by_freq = sorted(token_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Reserve special tokens\n",
    "stoi = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "\n",
    "# Add all tokens to vocabulary\n",
    "for token, _ in sorted_by_freq:\n",
    "    stoi[token] = len(stoi)\n",
    "\n",
    "# Create inverse mapping if needed later\n",
    "itos = {index: token for token, index in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d899f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<unk>': 1,\n",
       " 'the': 2,\n",
       " 'and': 3,\n",
       " 'a': 4,\n",
       " 'of': 5,\n",
       " 'to': 6,\n",
       " 'is': 7,\n",
       " 'it': 8,\n",
       " 'in': 9,\n",
       " 'i': 10,\n",
       " 'this': 11,\n",
       " 'that': 12,\n",
       " 's': 13,\n",
       " 'was': 14,\n",
       " 'as': 15,\n",
       " 'for': 16,\n",
       " 'with': 17,\n",
       " 'movie': 18,\n",
       " 'but': 19,\n",
       " 'film': 20,\n",
       " 't': 21,\n",
       " 'on': 22,\n",
       " 'you': 23,\n",
       " 'not': 24,\n",
       " 'he': 25,\n",
       " 'are': 26,\n",
       " 'his': 27,\n",
       " 'have': 28,\n",
       " 'one': 29,\n",
       " 'be': 30,\n",
       " 'all': 31,\n",
       " 'at': 32,\n",
       " 'they': 33,\n",
       " 'by': 34,\n",
       " 'an': 35,\n",
       " 'who': 36,\n",
       " 'so': 37,\n",
       " 'from': 38,\n",
       " 'like': 39,\n",
       " 'there': 40,\n",
       " 'her': 41,\n",
       " 'or': 42,\n",
       " 'just': 43,\n",
       " 'about': 44,\n",
       " 'out': 45,\n",
       " 'has': 46,\n",
       " 'if': 47,\n",
       " 'what': 48,\n",
       " 'some': 49,\n",
       " 'good': 50,\n",
       " 'can': 51,\n",
       " 'she': 52,\n",
       " 'when': 53,\n",
       " 'very': 54,\n",
       " 'more': 55,\n",
       " 'up': 56,\n",
       " 'even': 57,\n",
       " 'time': 58,\n",
       " 'no': 59,\n",
       " 'my': 60,\n",
       " 'would': 61,\n",
       " 'which': 62,\n",
       " 'story': 63,\n",
       " 'only': 64,\n",
       " 'really': 65,\n",
       " 'see': 66,\n",
       " 'had': 67,\n",
       " 'their': 68,\n",
       " 'we': 69,\n",
       " 'were': 70,\n",
       " 'me': 71,\n",
       " 'well': 72,\n",
       " 'than': 73,\n",
       " 'much': 74,\n",
       " 'get': 75,\n",
       " 'been': 76,\n",
       " 'will': 77,\n",
       " 'bad': 78,\n",
       " 'other': 79,\n",
       " 'people': 80,\n",
       " 'do': 81,\n",
       " 'also': 82,\n",
       " 'first': 83,\n",
       " 'because': 84,\n",
       " 'great': 85,\n",
       " 'into': 86,\n",
       " 'him': 87,\n",
       " 'how': 88,\n",
       " 'don': 89,\n",
       " 'most': 90,\n",
       " 'made': 91,\n",
       " 'its': 92,\n",
       " 'then': 93,\n",
       " 'way': 94,\n",
       " 'make': 95,\n",
       " 'could': 96,\n",
       " 'them': 97,\n",
       " 'too': 98,\n",
       " 'after': 99,\n",
       " 'any': 100,\n",
       " 'movies': 101,\n",
       " 'think': 102,\n",
       " 'characters': 103,\n",
       " 'watch': 104,\n",
       " 'films': 105,\n",
       " 'two': 106,\n",
       " 'character': 107,\n",
       " 'many': 108,\n",
       " 'life': 109,\n",
       " 'seen': 110,\n",
       " 'being': 111,\n",
       " 'plot': 112,\n",
       " 'where': 113,\n",
       " 'acting': 114,\n",
       " 'love': 115,\n",
       " 'little': 116,\n",
       " 'best': 117,\n",
       " 'never': 118,\n",
       " 'over': 119,\n",
       " 'show': 120,\n",
       " 'did': 121,\n",
       " 'know': 122,\n",
       " 'ever': 123,\n",
       " 'off': 124,\n",
       " 'man': 125,\n",
       " 'does': 126,\n",
       " 'here': 127,\n",
       " 'better': 128,\n",
       " 'your': 129,\n",
       " 'still': 130,\n",
       " 'end': 131,\n",
       " 'these': 132,\n",
       " 'say': 133,\n",
       " 'while': 134,\n",
       " 'scene': 135,\n",
       " 'scenes': 136,\n",
       " 'why': 137,\n",
       " 'something': 138,\n",
       " 'go': 139,\n",
       " 've': 140,\n",
       " 'such': 141,\n",
       " 'm': 142,\n",
       " 'should': 143,\n",
       " 'back': 144,\n",
       " 'through': 145,\n",
       " 'real': 146,\n",
       " 'those': 147,\n",
       " 'now': 148,\n",
       " 'watching': 149,\n",
       " 'though': 150,\n",
       " 'old': 151,\n",
       " 'thing': 152,\n",
       " 'doesn': 153,\n",
       " 're': 154,\n",
       " 'director': 155,\n",
       " 'actors': 156,\n",
       " 'years': 157,\n",
       " 'work': 158,\n",
       " 'new': 159,\n",
       " 'another': 160,\n",
       " 'funny': 161,\n",
       " 'didn': 162,\n",
       " '10': 163,\n",
       " 'before': 164,\n",
       " 'nothing': 165,\n",
       " 'actually': 166,\n",
       " 'makes': 167,\n",
       " 'look': 168,\n",
       " 'find': 169,\n",
       " 'few': 170,\n",
       " 'going': 171,\n",
       " 'same': 172,\n",
       " 'part': 173,\n",
       " 'again': 174,\n",
       " 'every': 175,\n",
       " 'lot': 176,\n",
       " 'world': 177,\n",
       " 'cast': 178,\n",
       " 'us': 179,\n",
       " 'down': 180,\n",
       " 'quite': 181,\n",
       " 'pretty': 182,\n",
       " 'want': 183,\n",
       " 'things': 184,\n",
       " 'horror': 185,\n",
       " 'however': 186,\n",
       " 'seems': 187,\n",
       " 'young': 188,\n",
       " 'around': 189,\n",
       " 'got': 190,\n",
       " 'big': 191,\n",
       " 'take': 192,\n",
       " 'fact': 193,\n",
       " 'thought': 194,\n",
       " 'enough': 195,\n",
       " 'long': 196,\n",
       " 'series': 197,\n",
       " 'both': 198,\n",
       " 'may': 199,\n",
       " 'original': 200,\n",
       " 'action': 201,\n",
       " 'between': 202,\n",
       " 'right': 203,\n",
       " 'own': 204,\n",
       " 'give': 205,\n",
       " 'family': 206,\n",
       " 'times': 207,\n",
       " 'comedy': 208,\n",
       " 'always': 209,\n",
       " 'point': 210,\n",
       " 'must': 211,\n",
       " 'gets': 212,\n",
       " 'come': 213,\n",
       " 'without': 214,\n",
       " 'isn': 215,\n",
       " 'almost': 216,\n",
       " 'saw': 217,\n",
       " 'interesting': 218,\n",
       " 'least': 219,\n",
       " 'role': 220,\n",
       " 'whole': 221,\n",
       " 'bit': 222,\n",
       " 'done': 223,\n",
       " 'music': 224,\n",
       " 'script': 225,\n",
       " 'd': 226,\n",
       " 'guy': 227,\n",
       " 'making': 228,\n",
       " 'far': 229,\n",
       " 'anything': 230,\n",
       " 'feel': 231,\n",
       " 'last': 232,\n",
       " '2': 233,\n",
       " 'might': 234,\n",
       " 'minutes': 235,\n",
       " 'll': 236,\n",
       " 'girl': 237,\n",
       " 'performance': 238,\n",
       " 'since': 239,\n",
       " 'kind': 240,\n",
       " 'probably': 241,\n",
       " 'day': 242,\n",
       " 'woman': 243,\n",
       " 'am': 244,\n",
       " 'fun': 245,\n",
       " 'away': 246,\n",
       " 'yet': 247,\n",
       " 'worst': 248,\n",
       " 'tv': 249,\n",
       " 'rather': 250,\n",
       " 'sure': 251,\n",
       " 'hard': 252,\n",
       " 'anyone': 253,\n",
       " 'each': 254,\n",
       " 'especially': 255,\n",
       " 'found': 256,\n",
       " 'having': 257,\n",
       " 'played': 258,\n",
       " 'although': 259,\n",
       " 'course': 260,\n",
       " 'our': 261,\n",
       " 'comes': 262,\n",
       " 'looking': 263,\n",
       " 'set': 264,\n",
       " 'screen': 265,\n",
       " 'believe': 266,\n",
       " 'looks': 267,\n",
       " 'trying': 268,\n",
       " 'goes': 269,\n",
       " 'book': 270,\n",
       " 'place': 271,\n",
       " 'put': 272,\n",
       " 'different': 273,\n",
       " 'once': 274,\n",
       " 'actor': 275,\n",
       " 'year': 276,\n",
       " 'money': 277,\n",
       " 'true': 278,\n",
       " 'sense': 279,\n",
       " 'ending': 280,\n",
       " 'dvd': 281,\n",
       " 'shows': 282,\n",
       " 'reason': 283,\n",
       " 'someone': 284,\n",
       " 'wasn': 285,\n",
       " 'let': 286,\n",
       " 'maybe': 287,\n",
       " 'worth': 288,\n",
       " 'three': 289,\n",
       " 'everything': 290,\n",
       " 'job': 291,\n",
       " 'everyone': 292,\n",
       " 'main': 293,\n",
       " 'plays': 294,\n",
       " 'said': 295,\n",
       " 'american': 296,\n",
       " 'instead': 297,\n",
       " 'audience': 298,\n",
       " 'together': 299,\n",
       " 'john': 300,\n",
       " 'play': 301,\n",
       " 'effects': 302,\n",
       " 'takes': 303,\n",
       " 'watched': 304,\n",
       " 'beautiful': 305,\n",
       " 'later': 306,\n",
       " 'house': 307,\n",
       " 'seem': 308,\n",
       " 'during': 309,\n",
       " '1': 310,\n",
       " 'night': 311,\n",
       " 'himself': 312,\n",
       " 'version': 313,\n",
       " 'wife': 314,\n",
       " 'high': 315,\n",
       " 'left': 316,\n",
       " 'seeing': 317,\n",
       " 'half': 318,\n",
       " 'father': 319,\n",
       " 'star': 320,\n",
       " 'special': 321,\n",
       " 'war': 322,\n",
       " 'excellent': 323,\n",
       " 'shot': 324,\n",
       " 'idea': 325,\n",
       " 'nice': 326,\n",
       " 'else': 327,\n",
       " 'black': 328,\n",
       " 'mind': 329,\n",
       " 'second': 330,\n",
       " 'simply': 331,\n",
       " 'less': 332,\n",
       " 'fan': 333,\n",
       " 'used': 334,\n",
       " 'read': 335,\n",
       " 'kids': 336,\n",
       " 'dead': 337,\n",
       " 'death': 338,\n",
       " '3': 339,\n",
       " 'help': 340,\n",
       " 'top': 341,\n",
       " 'poor': 342,\n",
       " 'completely': 343,\n",
       " 'men': 344,\n",
       " 'classic': 345,\n",
       " 'hollywood': 346,\n",
       " 'either': 347,\n",
       " 'enjoy': 348,\n",
       " 'performances': 349,\n",
       " 'home': 350,\n",
       " 'line': 351,\n",
       " 'short': 352,\n",
       " 'production': 353,\n",
       " 'given': 354,\n",
       " 'rest': 355,\n",
       " 'boring': 356,\n",
       " 'try': 357,\n",
       " 'women': 358,\n",
       " 'budget': 359,\n",
       " 'wrong': 360,\n",
       " 'need': 361,\n",
       " 'friends': 362,\n",
       " 'use': 363,\n",
       " 'full': 364,\n",
       " 'low': 365,\n",
       " 'until': 366,\n",
       " 'along': 367,\n",
       " 'couple': 368,\n",
       " 'camera': 369,\n",
       " 'truly': 370,\n",
       " 'stupid': 371,\n",
       " 'episode': 372,\n",
       " 'remember': 373,\n",
       " 'video': 374,\n",
       " 'moments': 375,\n",
       " 'start': 376,\n",
       " 'stars': 377,\n",
       " 'awful': 378,\n",
       " 'recommend': 379,\n",
       " 'next': 380,\n",
       " 'wonderful': 381,\n",
       " 'perhaps': 382,\n",
       " 'mean': 383,\n",
       " 'tell': 384,\n",
       " 'came': 385,\n",
       " 'won': 386,\n",
       " 'school': 387,\n",
       " 'understand': 388,\n",
       " 'terrible': 389,\n",
       " 'face': 390,\n",
       " 'definitely': 391,\n",
       " 'sex': 392,\n",
       " 'keep': 393,\n",
       " 'name': 394,\n",
       " 'playing': 395,\n",
       " 'doing': 396,\n",
       " 'small': 397,\n",
       " 'getting': 398,\n",
       " 'gives': 399,\n",
       " 'written': 400,\n",
       " 'others': 401,\n",
       " 'person': 402,\n",
       " 'style': 403,\n",
       " 'head': 404,\n",
       " 'early': 405,\n",
       " 'human': 406,\n",
       " 'live': 407,\n",
       " 'boy': 408,\n",
       " 'perfect': 409,\n",
       " 'yes': 410,\n",
       " 'itself': 411,\n",
       " 'often': 412,\n",
       " 'lines': 413,\n",
       " 'dialogue': 414,\n",
       " 'lost': 415,\n",
       " 'piece': 416,\n",
       " 'case': 417,\n",
       " 'felt': 418,\n",
       " 'become': 419,\n",
       " 'finally': 420,\n",
       " 'children': 421,\n",
       " 'absolutely': 422,\n",
       " 'killer': 423,\n",
       " 'against': 424,\n",
       " 'title': 425,\n",
       " 'supposed': 426,\n",
       " 'mother': 427,\n",
       " 'entertaining': 428,\n",
       " 'couldn': 429,\n",
       " 'oh': 430,\n",
       " 'cinema': 431,\n",
       " 'liked': 432,\n",
       " 'sort': 433,\n",
       " 'hope': 434,\n",
       " 'picture': 435,\n",
       " 'white': 436,\n",
       " 'waste': 437,\n",
       " 'entire': 438,\n",
       " 'evil': 439,\n",
       " 'friend': 440,\n",
       " 'went': 441,\n",
       " 'based': 442,\n",
       " 'fans': 443,\n",
       " 'problem': 444,\n",
       " 'certainly': 445,\n",
       " 'worse': 446,\n",
       " 'overall': 447,\n",
       " 'several': 448,\n",
       " 'called': 449,\n",
       " 'loved': 450,\n",
       " 'becomes': 451,\n",
       " 'mr': 452,\n",
       " 'lives': 453,\n",
       " 'drama': 454,\n",
       " 'laugh': 455,\n",
       " 'beginning': 456,\n",
       " 'example': 457,\n",
       " 'already': 458,\n",
       " 'direction': 459,\n",
       " '5': 460,\n",
       " '4': 461,\n",
       " 'son': 462,\n",
       " 'unfortunately': 463,\n",
       " 'turn': 464,\n",
       " 'care': 465,\n",
       " 'despite': 466,\n",
       " 'final': 467,\n",
       " 'throughout': 468,\n",
       " 'under': 469,\n",
       " 'wanted': 470,\n",
       " 'michael': 471,\n",
       " 'dark': 472,\n",
       " 'child': 473,\n",
       " 'seemed': 474,\n",
       " 'amazing': 475,\n",
       " 'history': 476,\n",
       " 'heart': 477,\n",
       " 'b': 478,\n",
       " 'fine': 479,\n",
       " 'lead': 480,\n",
       " 'guess': 481,\n",
       " 'works': 482,\n",
       " 'genre': 483,\n",
       " 'close': 484,\n",
       " 'humor': 485,\n",
       " 'writing': 486,\n",
       " 'tries': 487,\n",
       " 'wants': 488,\n",
       " 'totally': 489,\n",
       " 'hand': 490,\n",
       " 'viewer': 491,\n",
       " 'quality': 492,\n",
       " 'turns': 493,\n",
       " 'behind': 494,\n",
       " 'act': 495,\n",
       " 'sound': 496,\n",
       " 'favorite': 497,\n",
       " 'flick': 498,\n",
       " 'guys': 499,\n",
       " 'enjoyed': 500,\n",
       " 'art': 501,\n",
       " 'town': 502,\n",
       " 'today': 503,\n",
       " 'days': 504,\n",
       " 'game': 505,\n",
       " 'side': 506,\n",
       " 'gave': 507,\n",
       " 'past': 508,\n",
       " 'able': 509,\n",
       " 'starts': 510,\n",
       " 'sometimes': 511,\n",
       " 'horrible': 512,\n",
       " 'kill': 513,\n",
       " 'god': 514,\n",
       " 'late': 515,\n",
       " 'kid': 516,\n",
       " 'soon': 517,\n",
       " 'etc': 518,\n",
       " 'actress': 519,\n",
       " 'directed': 520,\n",
       " 'run': 521,\n",
       " 'expect': 522,\n",
       " 'eyes': 523,\n",
       " 'girls': 524,\n",
       " 'writer': 525,\n",
       " 'hour': 526,\n",
       " 'blood': 527,\n",
       " 'thinking': 528,\n",
       " 'stuff': 529,\n",
       " 'car': 530,\n",
       " 'brilliant': 531,\n",
       " 'self': 532,\n",
       " 'highly': 533,\n",
       " 'parts': 534,\n",
       " 'fight': 535,\n",
       " 'city': 536,\n",
       " 'daughter': 537,\n",
       " 'stories': 538,\n",
       " 'themselves': 539,\n",
       " 'myself': 540,\n",
       " 'took': 541,\n",
       " 'obviously': 542,\n",
       " 'decent': 543,\n",
       " 'slow': 544,\n",
       " 'brother': 545,\n",
       " 'police': 546,\n",
       " 'moment': 547,\n",
       " 'killed': 548,\n",
       " 'voice': 549,\n",
       " 'matter': 550,\n",
       " 'type': 551,\n",
       " 'except': 552,\n",
       " 'hit': 553,\n",
       " 'feeling': 554,\n",
       " 'age': 555,\n",
       " 'anyway': 556,\n",
       " 'stop': 557,\n",
       " 'living': 558,\n",
       " 'leave': 559,\n",
       " 'james': 560,\n",
       " 'violence': 561,\n",
       " 'strong': 562,\n",
       " 'coming': 563,\n",
       " 'says': 564,\n",
       " 'chance': 565,\n",
       " 'involved': 566,\n",
       " 'lack': 567,\n",
       " 'known': 568,\n",
       " 'cannot': 569,\n",
       " 'happened': 570,\n",
       " 'roles': 571,\n",
       " 'heard': 572,\n",
       " 'wouldn': 573,\n",
       " 'gore': 574,\n",
       " 'particularly': 575,\n",
       " 'happens': 576,\n",
       " 'alone': 577,\n",
       " 'obvious': 578,\n",
       " 'cut': 579,\n",
       " 'murder': 580,\n",
       " 'complete': 581,\n",
       " 'ago': 582,\n",
       " 'extremely': 583,\n",
       " 'experience': 584,\n",
       " 'number': 585,\n",
       " 'attempt': 586,\n",
       " 'wonder': 587,\n",
       " 'david': 588,\n",
       " 'interest': 589,\n",
       " 'crap': 590,\n",
       " 'hell': 591,\n",
       " 'hero': 592,\n",
       " 'husband': 593,\n",
       " 'including': 594,\n",
       " 'king': 595,\n",
       " 'happen': 596,\n",
       " 'none': 597,\n",
       " 'sad': 598,\n",
       " 'simple': 599,\n",
       " 'career': 600,\n",
       " 'hilarious': 601,\n",
       " 'annoying': 602,\n",
       " 'possible': 603,\n",
       " 'told': 604,\n",
       " 'score': 605,\n",
       " 'musical': 606,\n",
       " 'save': 607,\n",
       " 'across': 608,\n",
       " 'serious': 609,\n",
       " 'yourself': 610,\n",
       " 'song': 611,\n",
       " 'please': 612,\n",
       " 'looked': 613,\n",
       " 'body': 614,\n",
       " 'exactly': 615,\n",
       " 'released': 616,\n",
       " 'group': 617,\n",
       " 'english': 618,\n",
       " 'hours': 619,\n",
       " 'cool': 620,\n",
       " 'cinematography': 621,\n",
       " 'jokes': 622,\n",
       " 'change': 623,\n",
       " 'seriously': 624,\n",
       " 'whose': 625,\n",
       " 'wish': 626,\n",
       " 'usual': 627,\n",
       " 'ok': 628,\n",
       " 'taken': 629,\n",
       " 'happy': 630,\n",
       " 'ridiculous': 631,\n",
       " 'somewhat': 632,\n",
       " 'running': 633,\n",
       " 'usually': 634,\n",
       " 'ends': 635,\n",
       " 'shown': 636,\n",
       " 'shots': 637,\n",
       " 'reality': 638,\n",
       " 'light': 639,\n",
       " 'power': 640,\n",
       " 'huge': 641,\n",
       " 'finds': 642,\n",
       " 'order': 643,\n",
       " 'opening': 644,\n",
       " 'jack': 645,\n",
       " 'major': 646,\n",
       " 'started': 647,\n",
       " 'mostly': 648,\n",
       " 'view': 649,\n",
       " 'scary': 650,\n",
       " 'documentary': 651,\n",
       " 'talking': 652,\n",
       " 'episodes': 653,\n",
       " 'level': 654,\n",
       " 'country': 655,\n",
       " 'opinion': 656,\n",
       " 'middle': 657,\n",
       " 'relationship': 658,\n",
       " 'novel': 659,\n",
       " 'talent': 660,\n",
       " 'saying': 661,\n",
       " 'room': 662,\n",
       " 'ones': 663,\n",
       " 'call': 664,\n",
       " 'earth': 665,\n",
       " 'strange': 666,\n",
       " 'rating': 667,\n",
       " '7': 668,\n",
       " 'modern': 669,\n",
       " 'female': 670,\n",
       " 'british': 671,\n",
       " 'taking': 672,\n",
       " 'songs': 673,\n",
       " 'important': 674,\n",
       " 'non': 675,\n",
       " 'events': 676,\n",
       " 'disappointed': 677,\n",
       " 'five': 678,\n",
       " 'word': 679,\n",
       " 'apparently': 680,\n",
       " '8': 681,\n",
       " 'due': 682,\n",
       " 'knew': 683,\n",
       " 'robert': 684,\n",
       " 'turned': 685,\n",
       " 'attention': 686,\n",
       " 'single': 687,\n",
       " 'basically': 688,\n",
       " 'four': 689,\n",
       " 'aren': 690,\n",
       " 'knows': 691,\n",
       " 'silly': 692,\n",
       " 'easily': 693,\n",
       " 'fast': 694,\n",
       " 'supporting': 695,\n",
       " 'comic': 696,\n",
       " 'class': 697,\n",
       " 'clearly': 698,\n",
       " 'television': 699,\n",
       " 'local': 700,\n",
       " 'entertainment': 701,\n",
       " 'cheap': 702,\n",
       " 'paul': 703,\n",
       " 'future': 704,\n",
       " 'rock': 705,\n",
       " 'bring': 706,\n",
       " 'problems': 707,\n",
       " 'richard': 708,\n",
       " 'tells': 709,\n",
       " 'thriller': 710,\n",
       " 'miss': 711,\n",
       " 'oscar': 712,\n",
       " 'sets': 713,\n",
       " 'straight': 714,\n",
       " 'lady': 715,\n",
       " 'george': 716,\n",
       " 'sequence': 717,\n",
       " 'similar': 718,\n",
       " 'o': 719,\n",
       " 'enjoyable': 720,\n",
       " 'upon': 721,\n",
       " 'moving': 722,\n",
       " 'beyond': 723,\n",
       " 'review': 724,\n",
       " 'words': 725,\n",
       " 'stand': 726,\n",
       " 'within': 727,\n",
       " 'eye': 728,\n",
       " 'ten': 729,\n",
       " 'giving': 730,\n",
       " 'message': 731,\n",
       " 'theater': 732,\n",
       " 'talk': 733,\n",
       " 'falls': 734,\n",
       " 'predictable': 735,\n",
       " 'red': 736,\n",
       " 'above': 737,\n",
       " 'release': 738,\n",
       " 'romantic': 739,\n",
       " 'mention': 740,\n",
       " 'whether': 741,\n",
       " 'sequel': 742,\n",
       " 'ways': 743,\n",
       " 'begins': 744,\n",
       " 'fantastic': 745,\n",
       " 'easy': 746,\n",
       " 'herself': 747,\n",
       " 'sister': 748,\n",
       " 'needs': 749,\n",
       " 'points': 750,\n",
       " 'theme': 751,\n",
       " 'appears': 752,\n",
       " 'team': 753,\n",
       " 'york': 754,\n",
       " 'named': 755,\n",
       " 'mystery': 756,\n",
       " 'add': 757,\n",
       " 'near': 758,\n",
       " 'die': 759,\n",
       " 'bunch': 760,\n",
       " 'elements': 761,\n",
       " 'haven': 762,\n",
       " 'dull': 763,\n",
       " 'hate': 764,\n",
       " 'lee': 765,\n",
       " 'feels': 766,\n",
       " 'tale': 767,\n",
       " 'working': 768,\n",
       " 'feature': 769,\n",
       " 'using': 770,\n",
       " '9': 771,\n",
       " 'effort': 772,\n",
       " 'storyline': 773,\n",
       " 'nearly': 774,\n",
       " 'viewers': 775,\n",
       " 'parents': 776,\n",
       " 'animation': 777,\n",
       " 'dialog': 778,\n",
       " 'clear': 779,\n",
       " 'typical': 780,\n",
       " 'actual': 781,\n",
       " 'tom': 782,\n",
       " 'among': 783,\n",
       " 'editing': 784,\n",
       " 'doubt': 785,\n",
       " 'follow': 786,\n",
       " 'general': 787,\n",
       " 'tried': 788,\n",
       " 'french': 789,\n",
       " 'surprised': 790,\n",
       " 'avoid': 791,\n",
       " 'peter': 792,\n",
       " 'stay': 793,\n",
       " 'buy': 794,\n",
       " 'means': 795,\n",
       " 'material': 796,\n",
       " 'famous': 797,\n",
       " 'comments': 798,\n",
       " 'period': 799,\n",
       " 'lots': 800,\n",
       " 'soundtrack': 801,\n",
       " 'check': 802,\n",
       " 'zombie': 803,\n",
       " 'minute': 804,\n",
       " 'figure': 805,\n",
       " 'dance': 806,\n",
       " 'showing': 807,\n",
       " 'viewing': 808,\n",
       " 'certain': 809,\n",
       " 'fall': 810,\n",
       " 'third': 811,\n",
       " 'sorry': 812,\n",
       " 'rent': 813,\n",
       " 'realistic': 814,\n",
       " 'leads': 815,\n",
       " 'disney': 816,\n",
       " 'brought': 817,\n",
       " 'form': 818,\n",
       " 'suspense': 819,\n",
       " 'season': 820,\n",
       " 'lame': 821,\n",
       " 'somehow': 822,\n",
       " 'kept': 823,\n",
       " 'atmosphere': 824,\n",
       " 'space': 825,\n",
       " 'move': 826,\n",
       " 'average': 827,\n",
       " 'whatever': 828,\n",
       " 'particular': 829,\n",
       " 'weak': 830,\n",
       " 'imagine': 831,\n",
       " 'filmed': 832,\n",
       " 'premise': 833,\n",
       " 'okay': 834,\n",
       " 'wait': 835,\n",
       " 'hear': 836,\n",
       " 'america': 837,\n",
       " 'eventually': 838,\n",
       " 'possibly': 839,\n",
       " 'greatest': 840,\n",
       " 'sexual': 841,\n",
       " 'reviews': 842,\n",
       " 'note': 843,\n",
       " 'subject': 844,\n",
       " 'baby': 845,\n",
       " 'believable': 846,\n",
       " 'romance': 847,\n",
       " 'nature': 848,\n",
       " 'deal': 849,\n",
       " 'indeed': 850,\n",
       " '20': 851,\n",
       " 'crime': 852,\n",
       " 'surprise': 853,\n",
       " 'forget': 854,\n",
       " 'gone': 855,\n",
       " 'screenplay': 856,\n",
       " 'joe': 857,\n",
       " 'difficult': 858,\n",
       " 'poorly': 859,\n",
       " 'street': 860,\n",
       " 'free': 861,\n",
       " 'dr': 862,\n",
       " 'leaves': 863,\n",
       " 'sequences': 864,\n",
       " 'sit': 865,\n",
       " 'killing': 866,\n",
       " 'society': 867,\n",
       " 'japanese': 868,\n",
       " 'stage': 869,\n",
       " 'meets': 870,\n",
       " 'needed': 871,\n",
       " 'de': 872,\n",
       " 'otherwise': 873,\n",
       " 'decided': 874,\n",
       " 'shame': 875,\n",
       " 'became': 876,\n",
       " 'imdb': 877,\n",
       " 'cheesy': 878,\n",
       " 'reading': 879,\n",
       " 'dog': 880,\n",
       " 'truth': 881,\n",
       " 'nor': 882,\n",
       " 'question': 883,\n",
       " 'footage': 884,\n",
       " 'hot': 885,\n",
       " 'expected': 886,\n",
       " 'memorable': 887,\n",
       " 'comment': 888,\n",
       " 'male': 889,\n",
       " 'learn': 890,\n",
       " 'earlier': 891,\n",
       " 'monster': 892,\n",
       " 'superb': 893,\n",
       " 'acted': 894,\n",
       " 'begin': 895,\n",
       " 'dramatic': 896,\n",
       " 'meet': 897,\n",
       " 'fantasy': 898,\n",
       " 'situation': 899,\n",
       " 'realize': 900,\n",
       " 'unless': 901,\n",
       " 'write': 902,\n",
       " 'sci': 903,\n",
       " 'fi': 904,\n",
       " 'features': 905,\n",
       " 'keeps': 906,\n",
       " 'weird': 907,\n",
       " 'credits': 908,\n",
       " 'mess': 909,\n",
       " 'writers': 910,\n",
       " 'badly': 911,\n",
       " 'perfectly': 912,\n",
       " 'incredibly': 913,\n",
       " 'laughs': 914,\n",
       " 'older': 915,\n",
       " 'quickly': 916,\n",
       " 'whom': 917,\n",
       " 'open': 918,\n",
       " 'girlfriend': 919,\n",
       " 'creepy': 920,\n",
       " 'crazy': 921,\n",
       " 'deep': 922,\n",
       " 'hands': 923,\n",
       " 'interested': 924,\n",
       " 'setting': 925,\n",
       " 'sounds': 926,\n",
       " 'beauty': 927,\n",
       " 'personal': 928,\n",
       " 'dream': 929,\n",
       " 'effect': 930,\n",
       " 'towards': 931,\n",
       " 'plus': 932,\n",
       " 'fire': 933,\n",
       " 'political': 934,\n",
       " 'apart': 935,\n",
       " 'development': 936,\n",
       " 'directors': 937,\n",
       " 'air': 938,\n",
       " 'forced': 939,\n",
       " 'battle': 940,\n",
       " 'unique': 941,\n",
       " 'box': 942,\n",
       " 'e': 943,\n",
       " 'secret': 944,\n",
       " 'plenty': 945,\n",
       " 'joke': 946,\n",
       " 'emotional': 947,\n",
       " 'bill': 948,\n",
       " 'forward': 949,\n",
       " 'previous': 950,\n",
       " 'powerful': 951,\n",
       " 'mark': 952,\n",
       " 'casting': 953,\n",
       " 'leading': 954,\n",
       " 'directing': 955,\n",
       " 'create': 956,\n",
       " 'admit': 957,\n",
       " 'jane': 958,\n",
       " 'ask': 959,\n",
       " 'doctor': 960,\n",
       " 'potential': 961,\n",
       " 'fighting': 962,\n",
       " 'result': 963,\n",
       " 'cute': 964,\n",
       " 'social': 965,\n",
       " 'appear': 966,\n",
       " 'worked': 967,\n",
       " 'rate': 968,\n",
       " 'outside': 969,\n",
       " 'dumb': 970,\n",
       " 'front': 971,\n",
       " 'portrayed': 972,\n",
       " 'background': 973,\n",
       " 'return': 974,\n",
       " '30': 975,\n",
       " 'meant': 976,\n",
       " 'total': 977,\n",
       " 'hardly': 978,\n",
       " 'brings': 979,\n",
       " 'twist': 980,\n",
       " 'married': 981,\n",
       " 'break': 982,\n",
       " 'present': 983,\n",
       " 'fails': 984,\n",
       " 'masterpiece': 985,\n",
       " 'missing': 986,\n",
       " 'business': 987,\n",
       " 'pay': 988,\n",
       " 'cop': 989,\n",
       " 'nudity': 990,\n",
       " 'expecting': 991,\n",
       " 'telling': 992,\n",
       " 'unlike': 993,\n",
       " 'reasons': 994,\n",
       " 'deserves': 995,\n",
       " 'christmas': 996,\n",
       " 'list': 997,\n",
       " '80': 998,\n",
       " 'western': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59fe0912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 1739, 7, 449, 721, 6, 301, 4, 787, 9, 4, 18, 44, 2, 1705, 2460, 186, 25, 7, 24]\n"
     ]
    }
   ],
   "source": [
    "# numericalize tokens\n",
    "def encode(tokens):\n",
    "    return [stoi.get(t, stoi[\"<unk>\"]) for t in tokens]\n",
    "\n",
    "\n",
    "sample = tokenizer(train_dataset[0][\"text\"])\n",
    "encoded = encode(sample)\n",
    "print(encoded[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595684e3",
   "metadata": {},
   "source": [
    "- define `text_pipeline` function to transform each text in the dataset accordingly and the `label_pipeline` function to convert each label to 1 or 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ccc331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'movie', 'was', 'great']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(\"This movie was great!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5090c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3-A: Define transformation functions (vocab → indices)\n",
    "\n",
    "def text_pipeline(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return [stoi.get(token, stoi[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "def label_pipeline(label):\n",
    "    return 1.0 if label == \"pos\" else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93303edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: label ...\n",
      "Tokens: ['label']\n",
      "Numerical: [6357]\n",
      "Label: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "label, text = train_dataset[0]\n",
    "\n",
    "print(\"Original:\", text[:100], \"...\")\n",
    "print(\"Tokens:\", tokenizer(text)[:10])\n",
    "print(\"Numerical:\", text_pipeline(text)[:10])\n",
    "print(\"Label:\", label_pipeline(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07244ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'An extra is called upon to play a general in a movie about the Russian Revolution. However, he is not any ordinary extra. He is Serguis Alexander, former commanding general of the Russia armies who is now being forced to relive the same scene, which he suffered professional and personal tragedy in, to satisfy the director who was once a revolutionist in Russia and was humiliated by Alexander. It can now be the time for this broken man to finally \"win\" his penultimate battle. This is one powerful movie with meticulous direction by Von Sternberg, providing the greatest irony in Alexander\\'s character in every way he can. Jannings deserved his Oscar for the role with a very moving performance playing the general at his peak and at his deepest valley. Powell lends a sinister support as the revenge minded director and Brent is perfect in her role with her face and movements showing so much expression as Jannings\\' love. All around brilliance. Rating, 10.', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "example = train_dataset[0]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d620a",
   "metadata": {},
   "source": [
    "- We will wrap the text encoding and label transformation function into the `collate_batch` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77185db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 3-B: wrap the encode and transformation function\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "\n",
    "    for sample in batch:\n",
    "        text = sample[\"text\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        label_list.append(float(label))  \n",
    "        \n",
    "        ids = torch.tensor(text_pipeline(text), dtype=torch.long)\n",
    "        text_list.append(ids)\n",
    "        lengths.append(len(ids))\n",
    "\n",
    "    label_list = torch.tensor(label_list, dtype=torch.float32)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(\n",
    "        text_list, \n",
    "        batch_first=True, \n",
    "        padding_value=stoi[\"<pad>\"]\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        padded_text_list.to(device),\n",
    "        label_list.to(device),\n",
    "        lengths.to(device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacadec5",
   "metadata": {},
   "source": [
    "- Let's the take the first batch and print the sizes of the individual elements before combining these into mini-batches, as well as the dimensions of the resulting mini-batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0bd95c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   35,  1739,     7,   449,   721,     6,   301,     4,   787,     9,\n",
      "             4,    18,    44,     2,  1705,  2460,   186,    25,     7,    24,\n",
      "           100,  1874,  1739,    25,     7, 34415,  3568,  1103,  7517,   787,\n",
      "             5,     2,  4991, 12401,    36,     7,   148,   111,   939,     6,\n",
      "         11598,     2,   172,   135,    62,    25,  3199,  1602,     3,   928,\n",
      "          1500,     9,     6,  4601,     2,   155,    36,    14,   274,     4,\n",
      "         42945,     9,  4991,     3,    14, 10296,    34,  3568,     8,    51,\n",
      "           148,    30,     2,    58,    16,    11,  1893,   125,     6,   420,\n",
      "          1214,    27, 14542,   940,    11,     7,    29,   951,    18,    17,\n",
      "         15994,   459,    34,  2480, 15211,  3713,     2,   840,  3200,     9,\n",
      "          3568,    13,   107,     9,   175,    94,    25,    51, 10297,  1796,\n",
      "            27,   712,    16,     2,   220,    17,     4,    54,   722,   238,\n",
      "           395,     2,   787,    32,    27,  5236,     3,    32,    27,  7252,\n",
      "          5118,  2461,  6390,     4,  2873,  1495,    15,     2,  1054,  2874,\n",
      "           155,     3,  7015,     7,   409,     9,    41,   220,    17,    41,\n",
      "           390,     3,  3925,   807,    37,    74,  2858,    15, 10297,   115,\n",
      "            31,   189,  3506,   667,   163,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [  216,   175,   724,     5,    11,    18,    10,   226,   110,    14,\n",
      "           182,    78,     8,    13,    24,   182,    78,     8,    13,   166,\n",
      "           182,    50,   150,    24,    85,     2,  4031,  5935,   107,    96,\n",
      "            28,  1867,   602,    19,    52,   162,    21,  1698,     8,     6,\n",
      "          1181,   367,     2,   351,    10,   140,   419,     4,   333,     5,\n",
      "          6022,  7136,  5055,  1209, 10892,    32,   219,     9,     2,   405,\n",
      "          1413,    13,  4031,    13,  1099,     7,    85,    19,     2,    20,\n",
      "          1018,     4,    85,   565,    34,    24,   807,    55,     5,    68,\n",
      "           658,    10,   507,     8,     4,   668,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0],\n",
      "        [   10,   121,    24,    28,    98,    74,   589,     9,   149,     2,\n",
      "          7372,  3030, 14543,  1012,   520,     2,   985,  2327,     5, 16847,\n",
      "          5479,    19,    25,    67,    76,  3478,    38,     2,  7372,     3,\n",
      "            25,    67,    76,  2951,    34,    35, 10893,   155,   449, 29495,\n",
      "         23725,    10,    67,     2,   554,    12, 14543,    67,    91,     4,\n",
      "            50,    20,    19,     8,    67,    24,  4228,     2,  2142,    37,\n",
      "            33,  3478,    87,     3,  2564,   160,   155,    11,   634,   126,\n",
      "            24,   158,    72,   286,    13,   373,     2,  4804,    19,     2,\n",
      "          7372,  6794,     6,    30,   128,    73,    48,    10,   886,     8,\n",
      "            13,    24,     4,    85,    20,    19,     8,    13,    35,   218,\n",
      "             3,   428,   710,     2,   107,   936,     7,    54,    72,   223,\n",
      "             3,    10,    96,   122,     2,   103,    54,    72,    82,     2,\n",
      "           658,   202,     2,   106,   293,   103,     7,  1193,     3,  3031,\n",
      "           708,  5760,     3,  2918,  3991,   706,  3327,   349,   148,   286,\n",
      "            13,   139,     6,     2,  1501,   750,    29,  1407,    62,    65,\n",
      "          2612,    71,    40,    14,     4,   547,     9,    62,     8,  7943,\n",
      "            71,    14,     2,  5687,     5,  4868,  3111,     6,   205,     2,\n",
      "            18,    55,  2075,     3,   403,    12,  3111,   231,    45,     5,\n",
      "           271,     3,    68,  1400,     7,  9774,   932,    10,   102,     2,\n",
      "            20,   143,    28,    76,    55,  3810,     9,  2723,     5,    12,\n",
      "            10,   379,     2,  7372,    15,     4,    50,   710,     8,    13,\n",
      "            24,   887,    32,    31,    19,     8,    13,   428],\n",
      "        [18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
      "           502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
      "            90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
      "           847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
      "            32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
      "         10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
      "           630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
      "         18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
      "           214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
      "           597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
      "           289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
      "           111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
      "            66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
      "            78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
      "          3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0]],\n",
      "       device='mps:0')\n",
      "tensor([1., 1., 1., 0.], device='mps:0')\n",
      "tensor([165,  86, 218, 145], device='mps:0')\n",
      "torch.Size([4, 218])\n"
     ]
    }
   ],
   "source": [
    "## Take a small batch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)\n",
    "print(label_batch)\n",
    "print(length_batch)\n",
    "print(text_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17292918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18923,     7,     4,  4753,  1669,    12,  3019,     6,     4, 13906,\n",
       "          502,    40,    25,    77,  1588,     9,   115,     6, 21713,     2,\n",
       "           90,   305,   237,     9,   502,    33,    77,   376,     4, 16848,\n",
       "          847,    62,    77,   131,     9,     2,  1580,   338,     5, 18923,\n",
       "           32,     2,  1980,    49,   157,   306, 21713,    46,   981,     6,\n",
       "        10298,     2, 18924,   125,     9,   502,     3,   453,     4,  1852,\n",
       "          630,   407,  3407,    34,   277,    29,   242,     2, 20200,     5,\n",
       "        18923,    77,    95,    41,  1833,     6,  2105,    56,     3,   495,\n",
       "          214,   528,     2,  3479,     2,   112,     7,   181,  1813,     3,\n",
       "          597,     5,     2,   156,   294,     4,   543,   173,     9,  1562,\n",
       "          289, 10038,     5,     2,    20,    26,   841,  1392,    62,   130,\n",
       "          111,    72,   832,    26,   181, 12402,    15,    69,   183,     6,\n",
       "           66,    55,   936,     5,     2,    63,     8,     7,    43,     4,\n",
       "           78, 23726, 15995,    13,    20,    17,   800,     5,   392,    59,\n",
       "         3992,     3,   371,   103,  2596,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       device='mps:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_batch[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d3faf2",
   "metadata": {},
   "source": [
    "- The number of columns in the first batch is `128`, which resulted from combining the first four examples into a single batch and using the maximum size of these examples.\n",
    "- This means that the other three examples (whose lengths are 165, 86, and 145, respectively) in this batch are padded as much as necessary to match this size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc30f7",
   "metadata": {},
   "source": [
    "- Let's divide all three datasets into data loaders with a batch size of `32`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "938bfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 4: batching the datasets\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                      shuffle=True, collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
    "                      shuffle=False, collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fc3730",
   "metadata": {},
   "source": [
    "- Now, the data is in a suitable format for an `RNN` model, which we are going to implement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea63a76",
   "metadata": {},
   "source": [
    "### **Embedding layers for sentence encoding**\n",
    "\n",
    "During the data preparation in the previous step, we generated sequences of the same length. The elements of these sequences were integer numbers that corresponded to the indices of unique words. These word indices can be converted into input features in several different ways. One naive way is to apply `one-hot encoding` to convert the indices into vectors of zeros and ones. Then, each word will be mapped to a vector whose size is the number of unique words in the entire dataset. Given that the number of unique words (the size of the vocabulary) can be in the order of $10^{4}$ – $10^{5}$, which will also be the number of our input features, a model trained on such features may suffer from the `curse of dimensionality`. Furthermore, these features are very sparse since all are zero except one.\n",
    "\n",
    "\n",
    "A more elegant approach is to map each word to a vector of a fixed size with real-valued elements (not necessarily integers). In contrast to the one-hot encoded vectors, we can use finite-sized vectors to represent an infinite number of real numbers. (In theory, we can extract infinite real numbers from a given interval, for example `[–1, 1]`.)\n",
    "\n",
    "\n",
    "This is the idea behind embedding, which is a feature-learning technique that we can utilize here to automatically learn the `salient` features to represent the words in our dataset. Given the number of unique words, $n_{words}$, we can select the size of the embedding vectors (a.k.a., embedding dimension) to be much smaller than the number of unique words (embedding_dim << $`n_{words}`$) to represent the entire vocabulary as input features.\n",
    "\n",
    "\n",
    "The advantages of embedding over one-hot encoding are as follows:\n",
    "\n",
    "- A reduction in the dimensionality of the feature space to decrease the effect of the curse of dimensionality.\n",
    "- The extraction of salient features since the embedding layer in an `NN` can be optimized (or learned).\n",
    "\n",
    "\n",
    "`The following schematic representation shows how embedding works by mapping token indices to a trainable embedding matrix:`\n",
    "\n",
    "![A breakdown of how embedding works](./figures/15_10.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73115fff",
   "metadata": {},
   "source": [
    "- `input_dim`: number of words, i.e. maximum integer index + 1.\n",
    "  \n",
    "- `output_dim`:\n",
    "  \n",
    "- `input_length`: the length of (padded) sequence\n",
    "  - for example, `'This is an example' -> [0, 0, 0, 0, 0, 0, 3, 1, 8, 9]` => input_lenght is 10\n",
    "\n",
    "- When calling the layer, takes integr values as input, the embedding layer convert each interger into float vector of size `[output_dim]`\n",
    "  - If input shape is `[BATCH_SIZE]`, output shape will be `[BATCH_SIZE, output_dim]`\n",
    "  - If input shape is `[BATCH_SIZE, 10]`, output shape will be `[BATCH_SIZE, 10, output_dim]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff69b874",
   "metadata": {},
   "source": [
    "### **Embedding Layers for Sentence Encoding**\n",
    "\n",
    "`Embedding layers` convert text into dense vector representations for sentence encoding. These layers learn to map words or tokens to vectors where similar meanings are closer in the vector space. This allows models to process and compare sentences for tasks like similarity, information retrieval, and question answering by comparing the distance between their vector representations. Common approaches include using the output of a deep learning model's encoder, where each layer can capture different information, or using specialized sentence embedding models\n",
    "\n",
    "\n",
    "##### **1. Purpose**\n",
    "\n",
    "An embedding layer maps each discrete token (word, subword, or character) to a continuous vector representation. This allows neural networks to work with textual inputs efficiently by representing semantic and syntactic relations in a learned vector space.\n",
    "\n",
    "Given a vocabulary of size `V` and embedding dimension `d`, the embedding layer is a matrix:\n",
    "\n",
    "$$E \\in \\mathbb{R}^{V \\times d}$$\n",
    "\n",
    "A token with integer index `i` is represented as:\n",
    "\n",
    "$`x = E[i]`$\n",
    "\n",
    "\n",
    "##### **2. Sentence Representation**\n",
    "\n",
    "Suppose a sentence has token indices:\n",
    "\n",
    "$$[w_1, w_2, \\ldots, w_T]$$\n",
    "\n",
    "The embedding lookup gives:\n",
    "\n",
    "$`X = [E[w_1], E[w_2], \\ldots, E[w_T]]`$ \n",
    "$`X \\in \\mathbb{R}^{T \\times d}`$\n",
    "\n",
    "This matrix representation preserves word order and provides a dense representation per position.\n",
    "\n",
    "\n",
    "\n",
    "##### **3. Encoding Strategies**\n",
    "\n",
    "Once the tokens are embedded, several strategies can convert the sequence into a **single sentence representation**.\n",
    "\n",
    "(a) **Mean Pooling**\n",
    "\n",
    "$$h = \\frac{1}{T}\\sum_{t=1}^{T} X_t \\in \\mathbb{R}^{d}$$\n",
    "\n",
    "Captures coarse semantic information. Works surprisingly well for classification.\n",
    "\n",
    "\n",
    "(b) **Max Pooling**\n",
    "\n",
    "$$h_i = \\max_{t=1}^{T} X_{t,i}$$\n",
    "\n",
    "Highlights the most informative features across the sequence.\n",
    "\n",
    "\n",
    "(c) **RNN-based Encoding (e.g., LSTM, GRU)**\n",
    "\n",
    "Pass the sequence through RNN:\n",
    "\n",
    "$$h_t, c_t = \\mathrm{LSTM}(X_t, (h_{t-1}, c_{t-1}))$$\n",
    "\n",
    "Final hidden state:\n",
    "\n",
    "$$h_T \\in \\mathbb{R}^{d}$$\n",
    "\n",
    "This captures sequential and contextual dependencies, but with potential long-term dependency challenges.\n",
    "\n",
    "\n",
    "(d) **CNN-based Encoding**\n",
    "\n",
    "Apply convolution filters:\n",
    "\n",
    "$$H = \\mathrm{ReLU}(X * W + b)$$\n",
    "\n",
    "Then reduce via max-pooling:\n",
    "\n",
    "$$h = \\max(H)$$\n",
    "\n",
    "Captures local n-gram features efficiently.\n",
    "\n",
    "\n",
    "(e) **Transformer-based Encoding**\n",
    "\n",
    "Add positional encodings and process through self-attention layers:\n",
    "\n",
    "$$X = \\mathrm{TransformerEncoder}(X + P)$$\n",
    "\n",
    "Sentence representation often taken as mean-pooled output or `[CLS]` token vector.\n",
    "\n",
    "\n",
    "\n",
    "##### **4. Choice Considerations**\n",
    "\n",
    "| Method          | Captures Order  | Long-Range Context | Efficient for Long Sequences | Notes                             |\n",
    "| --------------- | --------------- | ------------------ | ---------------------------- | --------------------------------- |\n",
    "| Mean / Max Pool | No              | No                 | Yes                          | Fast; baseline                    |\n",
    "| LSTM / GRU      | Yes             | Limited            | Moderate                     | Good for moderate sentence length |\n",
    "| CNN             | Partial (local) | No                 | Yes                          | Good for phrase-level patterns    |\n",
    "| Transformer     | Yes             | Yes                | Expensive for very long seqs | Best general performance          |\n",
    "\n",
    "\n",
    "\n",
    "##### **5. Embedding Initialization Approaches**\n",
    "\n",
    "1. **Random Learnable Embeddings**\n",
    "   Learned from scratch during training.\n",
    "\n",
    "2. **Pretrained Static Embeddings**\n",
    "   Examples: GloVe, Word2Vec.\n",
    "   Embeddings fixed; network learns task-specific layers.\n",
    "\n",
    "3. **Pretrained Contextual Embeddings**\n",
    "   Examples: BERT, RoBERTa, GPT embeddings.\n",
    "   Contextual and dynamic; state-of-the-art for sentence representation.\n",
    "\n",
    "\n",
    "\n",
    "##### **6. Key Insight**\n",
    "\n",
    "The embedding layer provides **semantic grounding**; however, the choice of sentence encoding mechanism determines how relationships across tokens are modeled. For structured sentence understanding and contextual meaning extraction, **sequence models (LSTM/Transformer)** or **attention-based pooling** generally outperform simple averaging.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b85b62",
   "metadata": {},
   "source": [
    "- Creating an `embedding layer` can simply be done using `nn.Embedding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae32508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "tensor([[[ 1.3519, -1.1674, -1.3222],\n",
      "         [-0.3867,  2.0638,  1.0079],\n",
      "         [-1.9005, -0.4193,  0.8100],\n",
      "         [ 0.3361,  0.9807, -1.3204]],\n",
      "\n",
      "        [[ 0.3361,  0.9807, -1.3204],\n",
      "         [-1.9005, -0.4193,  0.8100],\n",
      "         [-0.3867,  2.0638,  1.0079],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(\n",
    "    num_embeddings=10,\n",
    "    embedding_dim=3,\n",
    "    padding_idx=0\n",
    ")\n",
    "\n",
    "# a batch of 2 samples of 4 indices each\n",
    "text_encoded_input = torch.LongTensor([[1, 2, 3, 4], [4, 3, 2, 0]])\n",
    "print(text_encoded_input.shape)\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f354e7",
   "metadata": {},
   "source": [
    "- The input to this model (embedding layer) must have `rank 2` with the dimensionality `batchsize x input_length`, where `input_length` is the length of sequences (here 4).\n",
    "\n",
    "- For example, an `input_sequence` in the mini-batch could be `<1, 5, 9, 2>`, where each element of this sequence is the index of the unique words.\n",
    "\n",
    "- The output will have the dimensionality `batch_size x input_length x embedding_dim`, where `embedding_dim` is the size of the embedding features (here, set to 3).\n",
    "\n",
    "- `num_embeddings`, corresponds to the unique integer values that the model will receive as input (for instance, n + 2, set here to 10). Therefore, the embedding matrix in this case has the size `10x6`.\n",
    "\n",
    "- `padding_idx` indicates the token index for padding (here, 0), which, if specified, will not contribute to the gradient updates during training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83709aab",
   "metadata": {},
   "source": [
    "### **Building an RNN model**\n",
    "\n",
    "- combination of the `embedding layer`, the recurrent layers of the RNN, and the fully connected non-recurrent layers.\n",
    "- For the recurrent layers, we can use any of the following implementations:\n",
    "\n",
    "  - `RNN`: a regular RNN layer, that is, a fully connected recurrent layer.\n",
    "  - `LSTM`: a long short-term memory RNN, which is useful for capturing the long-term dependencies.\n",
    "  - `GRU`: a recurrent layer with a gated recurrent unit, as an alternative to LSTMs.\n",
    "\n",
    "\n",
    "- RNN layers:\n",
    "  - `nn.RNN(input_size, hidden_size, num_layers=1)`\n",
    "  - `nn.LSTM(..)`\n",
    "  - `nn.GRU(..)`\n",
    "  - `nn.RNN(input_size, hidden_size, num_layers=1, bidirectional=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab215e",
   "metadata": {},
   "source": [
    "- **Fully connected neural network with one hidden layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad859dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size,\n",
    "                          num_layers=2, batch_first=True)\n",
    "        # self.rnn = nn.GRU(input_size, hidden_size,\n",
    "        #                   num_layers=1, batch_first=True)\n",
    "        # self.rnn = nn.LSTM(input_size, hidden_size,\n",
    "        #                    num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        _, hidden = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        # we use the final hidden state from the last hidden layer as the input to the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "model = RNN(64, 32)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24b53808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rnn.num_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0e8d1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1760],\n",
       "        [-0.0766],\n",
       "        [-0.0272],\n",
       "        [ 0.1103],\n",
       "        [-0.3438]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.randn(5, 3, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6525a1d4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2d361",
   "metadata": {},
   "source": [
    "#### **Context: What an RNN-Based Text Model Does**\n",
    "\n",
    "When we build a model for sentences:\n",
    "\n",
    "1. Text is **tokenized into integer IDs**.\n",
    "2. Each token ID is converted into a **vector** using an **Embedding Layer**.\n",
    "3. The vectors are fed **one-time-step-at-a-time** into an **RNN**, such as GRU or LSTM.\n",
    "4. The final hidden state (or pooled states) is fed into a **Fully Connected Layer** to make predictions.\n",
    "\n",
    "So the architecture looks like:\n",
    "\n",
    "```\n",
    "[Tokens] → [Embedding] → [RNN] → [FC Layer] → Output\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Key Terms and What They Mean**\n",
    "\n",
    "Let’s break them down **in the order they affect the architecture**:\n",
    "\n",
    "| Term                                  | What It Means                                      | Where It Appears                | Typical Range                                  |\n",
    "| ------------------------------------- | -------------------------------------------------- | ------------------------------- | ---------------------------------------------- |\n",
    "| **Vocabulary Size (V)**               | Number of unique tokens/words in your dataset      | Embedding layer input dimension | 10k–100k for English text                      |\n",
    "| **Embedding Dimension (d)**           | Size of the learned vector per token               | Output of embedding layer       | 50, 100, 200, 300 (classic) / 128–768 (modern) |\n",
    "| **Input Size**                        | Equals the **embedding dimension**, not vocab size | RNN input dimension             | Same as embedding dim                          |\n",
    "| **Hidden Size (h)**                   | Size of RNN’s internal memory/state                | RNN layer hidden dimension      | 64, 128, 256, 512                              |\n",
    "| **Number of RNN Layers**              | Depth (stacking) of the recurrent layers           | RNN module parameter            | 1–4                                            |\n",
    "| **Fully Connected Layer Hidden Size** | Size of the classifier head                        | FC network                      | 32, 64, 128                                    |\n",
    "| **Output Size**                       | Number of output classes                           | Final FC layer                  | For sentiment: 1 or 2                          |\n",
    "\n",
    "\n",
    "\n",
    "#### **The Critical Relationships**\n",
    "\n",
    "This is where it clicks:\n",
    "\n",
    "**1. Embedding Layer**\n",
    "\n",
    "```python\n",
    "nn.Embedding(num_embeddings=V, embedding_dim=d)\n",
    "```\n",
    "\n",
    "* `num_embeddings = vocabulary size`\n",
    "* `embedding_dim = embedding dimension`\n",
    "\n",
    "**Output shape of Embedding:**\n",
    "\n",
    "```\n",
    "(Batch, Sequence Length, d)\n",
    "```\n",
    "\n",
    "**2. RNN Layer (LSTM / GRU)**\n",
    "\n",
    "```python\n",
    "nn.LSTM(input_size=d, hidden_size=h, num_layers=L)\n",
    "```\n",
    "\n",
    "* `input_size = embedding dimension`\n",
    "* `hidden_size = RNN memory size`\n",
    "* `num_layers = how many LSTMs stacked`\n",
    "\n",
    "**Output shape:**\n",
    "\n",
    "```\n",
    "All hidden states:  (Batch, Sequence Length, h)\n",
    "Final state:        (Batch, h)\n",
    "```\n",
    "\n",
    "**3. Fully Connected (Classifier Head)**\n",
    "\n",
    "```python\n",
    "nn.Linear(h, num_classes)\n",
    "```\n",
    "\n",
    "* Input = final RNN hidden state\n",
    "* Output = predicted label(s)\n",
    "\n",
    "\n",
    "\n",
    "#### **Putting it Together: Example Architecture**\n",
    "\n",
    "Suppose:\n",
    "\n",
    "* Vocabulary size = **10,000**\n",
    "* Embedding dim = **128**\n",
    "* LSTM hidden size = **256**\n",
    "* Number of layers = **2**\n",
    "* Binary classification → output size = **1**\n",
    "\n",
    "**Architecture:**\n",
    "\n",
    "```python\n",
    "Embedding(V=10000, d=128)\n",
    "LSTM(input_size=128, hidden_size=256, num_layers=2)\n",
    "Linear(256 → 1)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "#### **Choosing Good Values (Simple Rules)**\n",
    "\n",
    "| Component           | Smaller Dataset | Medium/Large Dataset |\n",
    "| ------------------- | --------------- | -------------------- |\n",
    "| Vocabulary size     | 5k–20k          | 20k–200k             |\n",
    "| Embedding dimension | 50–200          | 200–768              |\n",
    "| RNN hidden size     | 64–256          | 256–1024             |\n",
    "| Number of layers    | 1–2             | 2–4                  |\n",
    "\n",
    "\n",
    "\n",
    "#### **Why Transformers Replace RNNs**\n",
    "\n",
    "* RNNs process one word at a time → **sequential dependency**, slow.\n",
    "* They struggle to retain long-range context.\n",
    "* Transformers use **self-attention**, which lets every word attend to every other word **in parallel**.\n",
    "\n",
    "But **the data flow is the same**:\n",
    "\n",
    "```\n",
    "Tokens → Embedding → *Model* → Classification Layer\n",
    "```\n",
    "\n",
    "The only difference is the **middle block**.\n",
    "\n",
    "| Before     | Now                        |\n",
    "| ---------- | -------------------------- |\n",
    "| LSTM / GRU | Transformer Encoder Layers |\n",
    "\n",
    "Everything else (vocab size, embedding dim, classifier head) stays conceptually identical.\n",
    "\n",
    "\n",
    "\n",
    "#### **Mental Model Summary**\n",
    "\n",
    "If you remember just this:\n",
    "\n",
    "```\n",
    "Vocabulary Size → How many tokens the model knows.\n",
    "Embedding Dimension → How rich each token’s meaning is.\n",
    "Hidden Size → How much memory the RNN has.\n",
    "Number of Layers → How deep the reasoning stack is.\n",
    "FC Layer → Maps meaning → decision.\n",
    "```\n",
    "\n",
    "You can design architectures **confidently**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b0b51",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370692eb",
   "metadata": {},
   "source": [
    "### **Building an RNN model for the sentiment analysis task**\n",
    "\n",
    "- For long sequences, we are going to use an `LSTM` layer to account for long-range effects.\n",
    "\n",
    "- Create an `RNN` model for sentiment analysis, starting with an embedding layer producing word embeddings of feature size 20 (embed_dim=20).\n",
    "\n",
    "- Then, a recurrent layer of type `LSTM` will be added.\n",
    "\n",
    "- Finally, we will add a `fully connected layer` as a hidden layer and another `fully connected layer` as the output layer, which will return a single class-membership probability value via the logistic sigmoid activation as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efc2bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,\n",
    "                                      embed_dim,\n",
    "                                      padding_idx=0\n",
    "                                      )\n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
    "                           batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(\n",
    "            out, lengths.cpu().numpy(), enforce_sorted=False,\n",
    "            batch_first=True\n",
    "        )\n",
    "        out, (hidden, cell) = self.rnn(out)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "vocab_size = len(stoi)\n",
    "embed_dim = 20\n",
    "rnn_hidden_size = 64\n",
    "fc_hidden_size = 64\n",
    "\n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, \n",
    "            embed_dim, \n",
    "            rnn_hidden_size, \n",
    "            fc_hidden_size) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5261523c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(69025, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76862a5",
   "metadata": {},
   "source": [
    "- Now, we will develop the `train` function to train the model on the given dataset for one epoch and return the classification accuracy and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04dba356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:, 0]\n",
    "        loss = loss_fn(pred, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += (\n",
    "            (pred >= 0.5).float() == label_batch\n",
    "        ).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc / len(dataloader.dataset), \\\n",
    "        total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de131ab",
   "metadata": {},
   "source": [
    "- Similarly, we will develop the evaluate function to measure the model’s performance on a given dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9258bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            pred = model(text_batch, lengths)[:, 0]\n",
    "            loss = loss_fn(pred, label_batch)\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf6649",
   "metadata": {},
   "source": [
    "- The next step is to create a `loss function` and optimizer `(Adam optimizer)`. For a binary classification with a single class-membership probability output, we use the binary cross-entropy loss `(BCELoss)` as the loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "805e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798cce99",
   "metadata": {},
   "source": [
    "- Now we will train the model for 10 epochs and display the training and validation performances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Accuracy: 0.9781 Val_accuracy: 0.8598\n",
      "Epoch 1 Accuracy: 0.9872 Val_accuracy: 0.8694\n",
      "Epoch 2 Accuracy: 0.9901 Val_accuracy: 0.8640\n",
      "Epoch 3 Accuracy: 0.9913 Val_accuracy: 0.8518\n",
      "Epoch 4 Accuracy: 0.9941 Val_accuracy: 0.8576\n",
      "Epoch 5 Accuracy: 0.9933 Val_accuracy: 0.8528\n",
      "Epoch 6 Accuracy: 0.9969 Val_accuracy: 0.8416\n",
      "Epoch 7 Accuracy: 0.9951 Val_accuracy: 0.8564\n",
      "Epoch 8 Accuracy: 0.9983 Val_accuracy: 0.8576\n",
      "Epoch 9 Accuracy: 0.9996 Val_accuracy: 0.8588\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f\"Epoch {epoch} Accuracy: {acc_train:.4f}\"\n",
    "          f\" Val_accuracy: {acc_valid:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17c939",
   "metadata": {},
   "source": [
    "- After training this model for 10 epochs, we will evaluate it on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6552f217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.8540\n"
     ]
    }
   ],
   "source": [
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f'test_accuracy: {acc_test:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e66e278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text_batch, label_batch, lengths in dataloader:\n",
    "#     print(text_batch, label_batch, lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927075f",
   "metadata": {},
   "source": [
    "#### **More on the bidirectional RNN**\n",
    "\n",
    "In addition, we will set the `bidirectional` configuration of the `LSTM` to True, which will make the recurrent layer pass through the input sequences from both directions, start to end, as well as in the reverse direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39e4b86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, \n",
    "                                      embed_dim, \n",
    "                                      padding_idx=0) \n",
    "        self.rnn = nn.LSTM(embed_dim, rnn_hidden_size, \n",
    "                           batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size*2, fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, text, lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
    "        _, (hidden, cell) = self.rnn(out)\n",
    "        out = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size) \n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "df019f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(69025, 20, padding_idx=0)\n",
       "  (rnn): LSTM(20, 64, batch_first=True, bidirectional=True)\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8d23d",
   "metadata": {},
   "source": [
    "- The bidirectional RNN layer makes two passes over each input sequence: a forward pass and a reverse or backward pass (note that this is not to be confused with the forward and backward passes in the context of backpropagation). \n",
    "\n",
    "- The hidden states from both passes are concatenated at each time step and passed to the next layer. This allows the model to capture information from both past and future contexts, which can be particularly beneficial for tasks like sentiment analysis where understanding the full context of a sentence is important.\n",
    "\n",
    "- Other merge modes include summation, averaging, and multiplication of the hidden states from both directions instead of concatenation.\n",
    "\n",
    "- We can also try other types of recurrent layers, such as `GRU` or regular `RNN` layers, instead of the `LSTM` layer.\n",
    "\n",
    "- However, a model built with regualar RNN layers may not perform as well as LSTM or GRU layers, especially for longer sequences, due to the vanishing gradient problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "num_epochs = 10 \n",
    "\n",
    "torch.manual_seed(1)\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "IMDB = load_dataset(\"imdb\")\n",
    "\n",
    "test_dataset = IMDB(split='test')\n",
    "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                     shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f290c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f'test_accuracy: {acc_test:.4f}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8827f",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
